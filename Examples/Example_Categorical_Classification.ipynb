{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended to show an example with categorical classification, and tries to show some of the nuances . The dataloading and other aspects of the library are brushed over in this notebook without much explanation, see the Example Binary Classification notebook for more explanation around what the different loaders do, and whatnot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ABCD_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nda_dr = '/mnt/sdb2/2.0_ABCD_Data_Explorer/2.0_NDA_Data/'\n",
    "test_mapping_loc = nda_dr + 'ABCD_Release_ Notes_Data_Release_ 2.0/22. ABCD_Release_2.0_mapping_r.csv'\n",
    "test_data_loc = nda_dr + 'MRI/ABCD sMRI Part 1.csv'\n",
    "test_target_loc = nda_dr + 'Mental Health/ABCD Parent Demographics Survey.csv'\n",
    "test_exclusion_loc = '/home/sage/bader_things/invalid_pguids.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCD_ML object initialized\n",
      "Error: One or both provided column names do not exist!\n",
      "Loaded map file\n",
      "Loading /mnt/sdb2/2.0_ABCD_Data_Explorer/2.0_NDA_Data/MRI/ABCD sMRI Part 1.csv assumed to be dataset type: explorer\n",
      "dropped ['abcd_smrip101_id', 'dataset_id', 'smri_visitid'] columns by default due to dataset type\n",
      "Dropped 0 columns, per drop_keys argument\n",
      "Dropped 0 cols for all missing values\n",
      "Dropped 522 rows for missing values\n",
      "Dropped rows with missing data\n",
      "Filtered data for outliers with value:  0.0005\n",
      "Winsorized data with value:  0.001\n",
      "loaded shape:  (8725, 749)\n",
      "\n",
      "Total valid (overlapping subjects / not in exclusions) subjects = 8725\n",
      "\n",
      "Loading  /mnt/sdb2/2.0_ABCD_Data_Explorer/2.0_NDA_Data/Mental Health/ABCD Parent Demographics Survey.csv\n",
      "Encoded to 17 categories\n",
      "Final shape:  (11310, 17)\n",
      "\n",
      "Total valid (overlapping subjects / not in exclusions) subjects = 8336\n",
      "\n",
      "Total excluded subjects:  1137\n",
      "\n",
      "Total valid (overlapping subjects / not in exclusions) subjects = 7547\n",
      "\n",
      "Removing non overlapping + excluded subjects\n"
     ]
    }
   ],
   "source": [
    "ML = ABCD_ML.ABCD_ML(default_dataset_type='explorer')\n",
    "\n",
    "ML.load_name_map(loc = test_mapping_loc,\n",
    "                 source_name_col = \"NDAR name\",\n",
    "                 target_name_col = \"REDCap name/NDA alias\")\n",
    "\n",
    "ML.load_data(loc=test_data_loc,\n",
    "             dataset_type='explorer',\n",
    "             filter_outlier_percent=.0005, \n",
    "             winsorize_val=.001)\n",
    "\n",
    "ML.load_targets(loc=test_target_loc,\n",
    "                col_name='demo_relig_v2',\n",
    "                data_type='c')\n",
    "ML.load_exclusions(loc=test_exclusion_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV defined with stratifying behavior, over 17 unique values.\n"
     ]
    }
   ],
   "source": [
    "ML.define_validation_strategy(stratify=ML.original_targets_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are defining our validation strategy as stratifying over the target keys, as some of the religions have very little representation, and we could potentially throw errors if some value is not represented in one of the various validation folds - We still might if we use too much internal CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final data for modeling loaded shape: (7547, 766)\n",
      "Performed train/test split, train size: 6037 test size:  1510\n"
     ]
    }
   ],
   "source": [
    "ML.train_test_split(test_size=.2,\n",
    "                    random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No default metric passed, set to, weighted roc auc based on default problem type.\n",
      "No default extra params passed, set to empty dict\n",
      "Default params set.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.set_default_ML_params(problem_type = 'categorical',\n",
    "                         data_scaler = 'standard',\n",
    "                         n_splits = 2,\n",
    "                         n_repeats = 1,\n",
    "                         int_cv = 2,\n",
    "                         class_weight = 'balanced',\n",
    "                         n_jobs = 4,\n",
    "                         n_iter = 2,\n",
    "                         random_state = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: gs and rs are  Grid Search and Random Search\n",
      "Models with gs or rs will have their hyper-parameters tuned accordingly.\n",
      "\n",
      "Problem Type: categorical\n",
      "----------------------\n",
      "Avaliable models: \n",
      "\n",
      "Model str indicator:  dt classifier\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "Model str indicator:  dt classifier gs\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "\n",
      "Model str indicator:  gaussian nb\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.naive_bayes.GaussianNB'>\n",
      "\n",
      "Model str indicator:  knn classifier\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "\n",
      "Model str indicator:  knn classifier gs\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "\n",
      "Model str indicator:  light gbm classifier\n",
      "(MultiClass)\n",
      "Model object:  <class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "\n",
      "Model str indicator:  light gbm classifier rs\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "\n",
      "Model str indicator:  logistic\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "\n",
      "Model str indicator:  logistic cv\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>\n",
      "\n",
      "Model str indicator:  random forest classifier\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "\n",
      "Model str indicator:  random forest classifier cal\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.calibration.CalibratedClassifierCV'>\n",
      "\n",
      "Model str indicator:  random forest classifier rs\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "\n",
      "Model str indicator:  svm classifier\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.svm.classes.SVC'>\n",
      "\n",
      "Model str indicator:  svm classifier rs\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "\n",
      "Model str indicator:  dt classifier\n",
      "(MultiLabel)\n",
      "Model object:  <class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "Model str indicator:  dt classifier gs\n",
      "(MultiLabel)\n",
      "Model object:  <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "\n",
      "Model str indicator:  knn classifier\n",
      "(MultiLabel)\n",
      "Model object:  <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "\n",
      "Model str indicator:  knn classifier gs\n",
      "(MultiLabel)\n",
      "Model object:  <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "\n",
      "Model str indicator:  random forest classifier\n",
      "(MultiLabel)\n",
      "Model object:  <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "\n",
      "Model str indicator:  random forest classifier rs\n",
      "(MultiLabel)\n",
      "Model object:  <class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.show_model_types(problem_type='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Evaluate with:\n",
      "model_type = ['knn', 'rf']\n",
      "problem_type = categorical\n",
      "metric = ['macro roc auc', 'macro f1', 'samples roc auc', 'weighted recall', 'log', 'macro jaccard', 'weighted ap']\n",
      "data_scaler = ['standard', 'minmax']\n",
      "n_splits = 2\n",
      "n_repeats = 1\n",
      "int_cv = 2\n",
      "class_weight = balanced\n",
      "n_jobs = 4\n",
      "n_iter = 2\n",
      "random_state = 9\n",
      "extra_params = {}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sage/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sage/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metric:  macro roc auc\n",
      "Macro mean score:  0.5682030503113262\n",
      "Macro std in score:  0.0\n",
      "Micro mean score:  0.5682030503113262\n",
      "Micro std in score:  0.005678437035310513\n",
      "\n",
      "Metric:  macro f1\n",
      "Macro mean score:  0.01169100501596702\n",
      "Macro std in score:  0.0\n",
      "Micro mean score:  0.01169100501596702\n",
      "Micro std in score:  1.744405403755235e-05\n",
      "\n",
      "Metric:  samples roc auc\n",
      "Macro mean score:  0.8148876200402093\n",
      "Macro std in score:  0.0\n",
      "Micro mean score:  0.8148876200402093\n",
      "Micro std in score:  0.0008680203048471169\n",
      "\n",
      "Metric:  weighted recall\n",
      "Macro mean score:  0.11031994039942832\n",
      "Macro std in score:  0.0\n",
      "Micro mean score:  0.11031994039942832\n",
      "Micro std in score:  0.00016446570541574224\n",
      "\n",
      "Metric:  log\n",
      "Macro mean score:  3.058345971680958\n",
      "Macro std in score:  0.0\n",
      "Micro mean score:  3.058345971680958\n",
      "Micro std in score:  0.0830879798636861\n",
      "\n",
      "Metric:  macro jaccard\n",
      "Macro mean score:  0.006490486765711914\n",
      "Macro std in score:  0.0\n",
      "Micro mean score:  0.006490486765711914\n",
      "Micro std in score:  1.0752960181762816e-05\n",
      "\n",
      "Metric:  weighted average precision\n",
      "Macro mean score:  0.19449457363161943\n",
      "Macro std in score:  0.0\n",
      "Micro mean score:  0.19449457363161943\n",
      "Micro std in score:  0.0009278577017673845\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.56252461, 0.01167356, 0.8140196 , 0.11015547, 3.14143395,\n",
       "        0.00647973, 0.19356672],\n",
       "       [0.57388149, 0.01170845, 0.81575564, 0.11048441, 2.97525799,\n",
       "        0.00650124, 0.19542243]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bunch_of_metrics = ['macro roc auc', 'macro f1', 'samples roc auc', 'weighted recall',\n",
    "                    'log', 'macro jaccard', 'weighted ap']\n",
    "\n",
    "# Ensemble of all multilabel compatible classifiers\n",
    "ML.Evaluate(model_type = ['knn', 'rf'],\n",
    "            metric = bunch_of_metrics,\n",
    "            data_scaler = ['standard', 'minmax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Evaluate with:\n",
      "model_type = ['logistic', 'knn', 'rf']\n",
      "problem_type = categorical\n",
      "metric = ['macro roc auc', 'macro f1', 'weighted recall', 'log', 'macro jaccard', 'weighted ap']\n",
      "data_scaler = ['standard', 'minmax']\n",
      "n_splits = 2\n",
      "n_repeats = 1\n",
      "int_cv = 2\n",
      "class_weight = balanced\n",
      "n_jobs = 4\n",
      "n_iter = 2\n",
      "random_state = 9\n",
      "extra_params = {}\n",
      "\n",
      "Not all model types passed have multilabel support! Using multiclass instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sage/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metric:  multiclass macro roc auc\n",
      "Macro mean score:  0.6015382030604486\n",
      "Macro std in score:  0.0\n",
      "Micro mean score:  0.6015382030604486\n",
      "Micro std in score:  0.0005533275676887772\n",
      "\n",
      "Metric:  macro f1\n",
      "Macro mean score:  0.09591509987406238\n",
      "Macro std in score:  0.0\n",
      "Micro mean score:  0.09591509987406238\n",
      "Micro std in score:  0.00048704272832821027\n",
      "\n",
      "Metric:  weighted recall\n",
      "Macro mean score:  0.22991010525146627\n",
      "Macro std in score:  0.0\n",
      "Micro mean score:  0.22991010525146627\n",
      "Micro std in score:  0.0036327329886925303\n",
      "\n",
      "Metric:  log\n",
      "Macro mean score:  2.209158003592969\n",
      "Macro std in score:  0.0\n",
      "Micro mean score:  2.209158003592969\n",
      "Micro std in score:  0.006312540251169674\n",
      "\n",
      "Metric:  macro jaccard\n",
      "Macro mean score:  0.055771450946402\n",
      "Macro std in score:  0.0\n",
      "Micro mean score:  0.055771450946402\n",
      "Micro std in score:  0.0007542971937540416\n",
      "\n",
      "Metric:  multiclass weighted average precision\n",
      "Macro mean score:  0.2278608885966879\n",
      "Macro std in score:  0.0\n",
      "Micro mean score:  0.2278608885966879\n",
      "Micro std in score:  0.0012809639933269307\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.60098488, 0.09640214, 0.23354284, 2.20284546, 0.05652575,\n",
       "        0.22914185],\n",
       "       [0.60209153, 0.09542806, 0.22627737, 2.21547054, 0.05501715,\n",
       "        0.22657992]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del bunch_of_metrics[2]\n",
    "\n",
    "\n",
    "ML.Evaluate(model_type = ['logistic', 'knn', 'rf'],\n",
    "                metric = bunch_of_metrics,\n",
    "                data_scaler = ['standard', 'minmax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: gs and rs are  Grid Search and Random Search\n",
      "Models with gs or rs will have their hyper-parameters tuned accordingly.\n",
      "\n",
      "Problem Type: categorical\n",
      "----------------------\n",
      "Avaliable models: \n",
      "\n",
      "Model str indicator:  dt classifier\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "Model str indicator:  dt classifier gs\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "\n",
      "Model str indicator:  gaussian nb\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.naive_bayes.GaussianNB'>\n",
      "\n",
      "Model str indicator:  knn classifier\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "\n",
      "Model str indicator:  knn classifier gs\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "\n",
      "Model str indicator:  light gbm classifier\n",
      "(MultiClass)\n",
      "Model object:  <class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "\n",
      "Model str indicator:  light gbm classifier rs\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "\n",
      "Model str indicator:  logistic\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "\n",
      "Model str indicator:  logistic cv\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>\n",
      "\n",
      "Model str indicator:  random forest classifier\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "\n",
      "Model str indicator:  random forest classifier cal\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.calibration.CalibratedClassifierCV'>\n",
      "\n",
      "Model str indicator:  random forest classifier rs\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "\n",
      "Model str indicator:  svm classifier\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.svm.classes.SVC'>\n",
      "\n",
      "Model str indicator:  svm classifier rs\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "\n",
      "Model str indicator:  dt classifier\n",
      "(MultiLabel)\n",
      "Model object:  <class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "Model str indicator:  dt classifier gs\n",
      "(MultiLabel)\n",
      "Model object:  <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "\n",
      "Model str indicator:  knn classifier\n",
      "(MultiLabel)\n",
      "Model object:  <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "\n",
      "Model str indicator:  knn classifier gs\n",
      "(MultiLabel)\n",
      "Model object:  <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "\n",
      "Model str indicator:  random forest classifier\n",
      "(MultiLabel)\n",
      "Model object:  <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "\n",
      "Model str indicator:  random forest classifier rs\n",
      "(MultiLabel)\n",
      "Model object:  <class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.show_model_types(problem_type='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML.Evaluate(model_type = 'knn classifier',\n",
    "#           metric = 'hamming'\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML.Evaluate(model_type = 'knn classifier gs',\n",
    "#           metric = 'hamming'\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML.Evaluate(model_type = 'rf',\n",
    "#            metric = 'micro f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
