{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ABCD_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nda_dr = '/mnt/sdb2/2.0_ABCD_Data_Explorer/2.0_NDA_Data/'\n",
    "test_mapping_loc = nda_dr + 'ABCD_Release_ Notes_Data_Release_ 2.0/22. ABCD_Release_2.0_mapping_r.csv'\n",
    "test_data_loc = nda_dr + 'MRI/ABCD sMRI Part 1.csv'\n",
    "test_target_loc = nda_dr + 'Mental Health/ABCD Parent Demographics Survey.csv'\n",
    "test_exclusion_loc = '/home/sage/bader_things/invalid_pguids.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCD_ML object initialized\n",
      "Loaded map file\n",
      "Loading /mnt/sdb2/2.0_ABCD_Data_Explorer/2.0_NDA_Data/MRI/ABCD sMRI Part 1.csv assumed to be dataset type: explorer\n",
      "dropped ['abcd_smrip101_id', 'dataset_id', 'smri_visitid'] columns by default due to dataset type\n",
      "Dropped 0 columns, per drop_keys argument\n",
      "Dropped 0 cols for all missing values\n",
      "Dropped 522 rows for missing values\n",
      "Dropped rows with missing data\n",
      "Filtered data for outliers with value:  0.0005\n",
      "Winsorized data with value:  0.001\n",
      "loaded shape:  (8725, 749)\n",
      "\n",
      "Total valid (overlapping subjects / not in exclusions) subjects = 8725\n",
      "\n",
      "Loading  /mnt/sdb2/2.0_ABCD_Data_Explorer/2.0_NDA_Data/Mental Health/ABCD Parent Demographics Survey.csv\n",
      "Encoded to 17 categories\n",
      "Final shape:  (11310, 17)\n",
      "\n",
      "Total valid (overlapping subjects / not in exclusions) subjects = 8336\n",
      "\n",
      "Total excluded subjects:  1137\n",
      "\n",
      "Total valid (overlapping subjects / not in exclusions) subjects = 7547\n",
      "\n",
      "Removing non overlapping + excluded subjects\n"
     ]
    }
   ],
   "source": [
    "ML = ABCD_ML.ABCD_ML()\n",
    "\n",
    "ML.load_name_map(loc = test_mapping_loc,\n",
    "                 source_name_col = \"NDAR name\",\n",
    "                 target_name_col = \"REDCap name/NDA alias\")\n",
    "\n",
    "ML.load_data(loc=test_data_loc,\n",
    "             dataset_type='explorer',\n",
    "             filter_outlier_percent=.0005, \n",
    "             winsorize_val=.001)\n",
    "\n",
    "ML.load_targets(loc=test_target_loc,\n",
    "                col_name='demo_relig_v2',\n",
    "                data_type='c')\n",
    "ML.load_exclusions(loc=test_exclusion_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV defined with stratifying behavior, over 17 unique values.\n"
     ]
    }
   ],
   "source": [
    "ML.define_validation_strategy(stratify=ML.original_targets_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are defining our validation strategy as stratifying over the target keys, as some of the religions have very little representation, and we could potentially throw errors if some value is not represented in one of the various validation folds - We still might if we use too much internal CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final data for modeling loaded shape: (7547, 767)\n",
      "Performed train/test split, train size: 6037 test size:  1510\n"
     ]
    }
   ],
   "source": [
    "ML.train_test_split(test_size=.2,\n",
    "                    random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No default metric passed, set to, weighted roc auc based on default problem type.\n",
      "No default extra params passed, set to empty dict\n",
      "Default params set.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.set_default_ML_params(problem_type = 'categorical',\n",
    "                         data_scaler = 'standard',\n",
    "                         n_splits = 2,\n",
    "                         n_repeats = 1,\n",
    "                         int_cv = 2,\n",
    "                         class_weight = 'balanced',\n",
    "                         n_jobs = 4,\n",
    "                         n_iter = 2,\n",
    "                         random_state = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: gs and rs are  Grid Search and Random Search\n",
      "Models with gs or rs will have their hyper-parameters tuned accordingly.\n",
      "\n",
      "Problem Type: categorical\n",
      "----------------------\n",
      "Avaliable models: \n",
      "\n",
      "Model str indicator:  dt classifier\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "Model str indicator:  dt classifier gs\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "\n",
      "Model str indicator:  gaussian nb\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.naive_bayes.GaussianNB'>\n",
      "\n",
      "Model str indicator:  knn classifier\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "\n",
      "Model str indicator:  knn classifier gs\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "\n",
      "Model str indicator:  light gbm classifier\n",
      "(MultiClass)\n",
      "Model object:  <class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "\n",
      "Model str indicator:  light gbm classifier rs\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "\n",
      "Model str indicator:  logistic\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "\n",
      "Model str indicator:  logistic cv\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>\n",
      "\n",
      "Model str indicator:  random forest classifier\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "\n",
      "Model str indicator:  random forest classifier cal\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.calibration.CalibratedClassifierCV'>\n",
      "\n",
      "Model str indicator:  random forest classifier rs\n",
      "(MultiClass)\n",
      "Model object:  <class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "\n",
      "Model str indicator:  dt classifier\n",
      "(MultiLabel)\n",
      "Model object:  <class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "\n",
      "Model str indicator:  dt classifier gs\n",
      "(MultiLabel)\n",
      "Model object:  <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "\n",
      "Model str indicator:  knn classifier\n",
      "(MultiLabel)\n",
      "Model object:  <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "\n",
      "Model str indicator:  knn classifier gs\n",
      "(MultiLabel)\n",
      "Model object:  <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "\n",
      "Model str indicator:  random forest classifier\n",
      "(MultiLabel)\n",
      "Model object:  <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "\n",
      "Model str indicator:  random forest classifier rs\n",
      "(MultiLabel)\n",
      "Model object:  <class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.show_model_types(problem_type='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Evaluate with:\n",
      "model_type = random forest cal\n",
      "problem_type = categorical\n",
      "metric = macro precision\n",
      "data_scaler = standard\n",
      "n_splits = 2\n",
      "n_repeats = 1\n",
      "int_cv = 2\n",
      "class_weight = balanced\n",
      "n_jobs = 4\n",
      "n_iter = 2\n",
      "random_state = 9\n",
      "extra_params = {}\n",
      "\n",
      "Not all model types passed have multilabel support! Using multiclass instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sage/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro mean score:  0.37328278899086553\n",
      "Macro std in score:  0.0\n",
      "Micro mean score:  0.37328278899086553\n",
      "Micro std in score:  0.05119126408219368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sage/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3220915249086719, 0.42447405307305924]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML.Evaluate(model_type = 'random forest cal',\n",
    "            metric = 'macro precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Evaluate with:\n",
      "model_type = random forest cal\n",
      "problem_type = categorical\n",
      "metric = macro roc auc\n",
      "data_scaler = standard\n",
      "n_splits = 2\n",
      "n_repeats = 1\n",
      "int_cv = 2\n",
      "class_weight = balanced\n",
      "n_jobs = 4\n",
      "n_iter = 2\n",
      "random_state = 9\n",
      "extra_params = {}\n",
      "\n",
      "Not all model types passed have multilabel support! Using multiclass instead.\n",
      "Macro mean score:  0.8204773375764192\n",
      "Macro std in score:  0.0\n",
      "Micro mean score:  0.8204773375764192\n",
      "Micro std in score:  0.008550866658819045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8119264709176002, 0.8290282042352383]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML.Evaluate(model_type = 'random forest cal',\n",
    "            metric = 'macro roc auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Evaluate with:\n",
      "model_type = logistic cv\n",
      "problem_type = categorical\n",
      "metric = macro roc auc\n",
      "data_scaler = standard\n",
      "n_splits = 2\n",
      "n_repeats = 1\n",
      "int_cv = 2\n",
      "class_weight = balanced\n",
      "n_jobs = 4\n",
      "n_iter = 2\n",
      "random_state = 9\n",
      "extra_params = {}\n",
      "\n",
      "Not all model types passed have multilabel support! Using multiclass instead.\n"
     ]
    }
   ],
   "source": [
    "ML.Evaluate(model_type = 'logistic cv',\n",
    "            metric = 'macro roc auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML.Evaluate(model_type = 'knn classifier',\n",
    "#           metric = 'hamming'\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML.Evaluate(model_type = 'knn classifier gs',\n",
    "#           metric = 'hamming'\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML.Evaluate(model_type = 'rf',\n",
    "#            metric = 'micro f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
