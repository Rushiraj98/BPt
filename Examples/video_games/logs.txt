exp_name = video_games
log_dr = /home/sage/ABCD_ML/Examples
existing_log = overwrite
verbose = True
exp log dr setup at: /home/sage/ABCD_ML/Examples/video_games
log file at: /home/sage/ABCD_ML/Examples/video_games/logs.txt
notebook = True
default subject id col = src_subject_id
eventname = baseline_year_1_arm_1
use default subject ids = True
default dataset type = basic
default NaN values = ['777', '999']
low memory mode = False
random state = 1
ABCD_ML object initialized
Loading /mnt/sdb2/ABCDFixRelease2p0p1/Fix Release Notes 2.0.1_Public/24. ABCD_Release_2.0.1_Updates/abcd_2.0.1_mapping.csv assumed to be dataset type: explorer
Loaded map file
Loading /mnt/sdb2/ABCD2p0NDA/abcd_stq01.txt assumed to be dataset type: basic
4951 subjects dropped for eventname
Dropped 0 cols for all missing values
Dropped 37 rows for missing values, based on the provided drop_nan param: True with actual nan_thresh: 0
Loaded rows with NaN remaining: 0
loading: screen3_wkdy_y
loading: screen9_wknd_y
Final shape:  (11838, 2)

Total valid overlapping subjects = 11838

All loaded targets
0 : screen3_wkdy_y
1 : screen9_wknd_y
cleared targets.
-- gaming_hours --
       gaming_hours
count  11838.000000
mean       7.097166
std        7.752232
min        0.000000
25%        1.750000
50%        4.000000
75%        9.000000
max       28.000000

Num. of unique vals: 44


Binarizing gaming_hours
Keeping: 1208 as 1.
Keeping: 1976 as 0.

Total valid overlapping subjects = 3184

-- gaming_hours --
              Original Name  Counts  Frequency
Internal Name                                 
0.0                      <1    1976   0.620603
1.0                     >20    1208   0.379397


Loading /mnt/sdb2/ABCDFixRelease2p0p1/abcd_tfabwdp101.txt assumed to be dataset type: basic
dropped ['collection_id', 'abcd_tfabwdp101_id', 'dataset_id', 'subjectkey', 'interview_age', 'interview_date', 'sex', 'collection_title', 'study_cohort_name'] columns by default  due to dataset type

Loading /mnt/sdb2/ABCDFixRelease2p0p1/abcd_tfabwdp201.txt assumed to be dataset type: basic
dropped ['collection_id', 'abcd_tfabwdp201_id', 'dataset_id', 'subjectkey', 'interview_age', 'interview_date', 'sex', 'collection_title', 'study_cohort_name'] columns by default  due to dataset type

Loading /mnt/sdb2/ABCDFixRelease2p0p1/abcd_midabwdp01.txt assumed to be dataset type: basic
dropped ['collection_id', 'abcd_midabwdp01_id', 'dataset_id', 'subjectkey', 'interview_date', 'interview_age', 'sex', 'collection_title', 'study_cohort_name'] columns by default  due to dataset type

Loading /mnt/sdb2/ABCDFixRelease2p0p1/abcd_midabwdp202.txt assumed to be dataset type: basic
dropped ['collection_id', 'abcd_midabwdp202_id', 'dataset_id', 'subjectkey', 'interview_date', 'interview_age', 'sex', 'collection_title', 'study_cohort_name'] columns by default  due to dataset type

Loading /mnt/sdb2/ABCDFixRelease2p0p1/abcd_tfsstabwdp101.txt assumed to be dataset type: basic
dropped ['collection_id', 'abcd_tfsstabwdp101_id', 'dataset_id', 'subjectkey', 'interview_age', 'interview_date', 'sex', 'collection_title', 'study_cohort_name'] columns by default  due to dataset type

Loading /mnt/sdb2/ABCDFixRelease2p0p1/abcd_tfsstabwdp201.txt assumed to be dataset type: basic
dropped ['collection_id', 'abcd_tfsstabwdp201_id', 'dataset_id', 'subjectkey', 'interview_age', 'interview_date', 'sex', 'collection_title', 'study_cohort_name'] columns by default  due to dataset type

Dropped 0 columns, per drop_keys argument
Dropped 0 cols for all missing values
Dropped 64 rows for missing values, based on the provided drop_nan param: True with actual nan_thresh: 0
Loaded rows with NaN remaining: 0

loaded shape:  (7780, 3848)

Total valid overlapping subjects = 2050

Cleared loaded data.

Loading /mnt/sdb2/ABCDFixRelease2p0p1/abcd_tfabwdp101.txt assumed to be dataset type: basic
dropped ['collection_id', 'abcd_tfabwdp101_id', 'dataset_id', 'subjectkey', 'interview_age', 'interview_date', 'sex', 'collection_title', 'study_cohort_name'] columns by default  due to dataset type

Loading /mnt/sdb2/ABCDFixRelease2p0p1/abcd_tfabwdp201.txt assumed to be dataset type: basic
dropped ['collection_id', 'abcd_tfabwdp201_id', 'dataset_id', 'subjectkey', 'interview_age', 'interview_date', 'sex', 'collection_title', 'study_cohort_name'] columns by default  due to dataset type

Loading /mnt/sdb2/ABCDFixRelease2p0p1/abcd_midabwdp01.txt assumed to be dataset type: basic
dropped ['collection_id', 'abcd_midabwdp01_id', 'dataset_id', 'subjectkey', 'interview_date', 'interview_age', 'sex', 'collection_title', 'study_cohort_name'] columns by default  due to dataset type

Loading /mnt/sdb2/ABCDFixRelease2p0p1/abcd_midabwdp202.txt assumed to be dataset type: basic
dropped ['collection_id', 'abcd_midabwdp202_id', 'dataset_id', 'subjectkey', 'interview_date', 'interview_age', 'sex', 'collection_title', 'study_cohort_name'] columns by default  due to dataset type

Loading /mnt/sdb2/ABCDFixRelease2p0p1/abcd_tfsstabwdp101.txt assumed to be dataset type: basic
dropped ['collection_id', 'abcd_tfsstabwdp101_id', 'dataset_id', 'subjectkey', 'interview_age', 'interview_date', 'sex', 'collection_title', 'study_cohort_name'] columns by default  due to dataset type

Loading /mnt/sdb2/ABCDFixRelease2p0p1/abcd_tfsstabwdp201.txt assumed to be dataset type: basic
dropped ['collection_id', 'abcd_tfsstabwdp201_id', 'dataset_id', 'subjectkey', 'interview_age', 'interview_date', 'sex', 'collection_title', 'study_cohort_name'] columns by default  due to dataset type

Dropped 0 columns, per drop_keys argument
Dropped 0 cols for all missing values
Dropped 64 rows for missing values, based on the provided drop_nan param: True with actual nan_thresh: 0
Loaded rows with NaN remaining: 0

Winsorized data with value:  0.002
loaded shape:  (7780, 3848)

Total valid overlapping subjects = 2050

Reading strat/stratification values!
Loading /mnt/sdb2/ABCDFixRelease2p0p1/abcd_midabwdp01.txt assumed to be dataset type: basic
Dropped 0 cols for all missing values
Dropped 1 rows for missing values, based on the provided drop_nan param: True with actual nan_thresh: 0
Loaded rows with NaN remaining: 0

Total valid overlapping subjects = 2050

Removing non overlapping subjects
Reading strat/stratification values!
Loading /mnt/sdb2/2.0_ABCD_Data_Explorer/2.0_NDA_Data/Other Non-Imaging/ABCD ACS Post Stratification Weights.csv assumed to be dataset type: explorer
Dropped 0 cols for all missing values
Dropped 2 rows for missing values, based on the provided drop_nan param: True with actual nan_thresh: 0
Loaded rows with NaN remaining: 0
Merged with existing!
New combined shape: (2050, 2)

Total valid overlapping subjects = 2050

Removing non overlapping subjects
CV defined with group preserving over 1959 unique values.
Final data (w/ target) for modeling loaded shape: (2050, 3851)
Performed train/test split, train size: 1632 test size:  418
No default target passed, set to 0.
No default model type passed, set to linear.
No default imputer passed, set to [mean, median]
No default imputer scope passed, set to [float, categorical]
No default sampler passed, set to None
No default sample on passed, set to targets
No default feat selector passed, set to None
No default ensemble type passed, set to basic ensemble
No default ensemble split passed, set to .2
No default model param ind passed, set to 0
No default imputer scaler params passed, set to 0
No default data scaler params passed, set to 0
No default sampler params passed, set to 0
No default feat selector params passed, set to 0
No default ensemble type params passed, set to 0
No default subjects_to_use passed, set to all
No default compute_train_score passed, set to False
No default random state passed, using class random state value of 1
No default calc_base_feature_importances passed, set to True
No default calc_shap_feature_importances passed, set to False
No default extra params passed, set to empty dict
Default params set.

Setting default ML verbosity settings!
Note, if the following values are not desired, call self.Set_ML_Verbosity()

Running Evaluate with:
problem_type = binary
model = light gbm
model_params = 1
metric = ['matthews', 'macro roc auc', 'balanced accuracy', 'f1']
scaler = robust
scaler_scope = all
scaler_params = 0
sampler = None
feat_selector = univariate selection
feat_selector_params = 1
splits = 3
n_repeats = 2
search_type = random
search_splits = 3
search_n_iter = 50
n_jobs = 7
feats_to_use = _sst_
subjects_to_use = ('sex', 0)
compute_train_score = False
random_state = 1
calc_base_feature_importances = True
calc_shap_feature_importances = True
extra_params = {}

Saving scores and settings with unique name: light gbm

subjects_to_use set to: sex=0,


Validation Scores
_________________
Metric:  matthews
Mean Validation score:  0.04729526227922565
Macro Std in Validation score:  0.002013523743589596
Micro Std in Validation score:  0.04483705189072966

Metric:  macro roc auc
Mean Validation score:  0.5526160677920591
Macro Std in Validation score:  0.02156029597307413
Micro Std in Validation score:  0.03822013201909591

Metric:  balanced accuracy
Mean Validation score:  0.5370120003401185
Macro Std in Validation score:  0.004806661598999229
Micro Std in Validation score:  0.026501249625268956

Metric:  f1
Mean Validation score:  0.1884799856294948
Macro Std in Validation score:  0.02728777151757264
Micro Std in Validation score:  0.08838080341568016

Running Evaluate with:
problem_type = binary
model = light gbm
model_params = 1
metric = ['matthews', 'macro roc auc', 'balanced accuracy', 'f1']
scaler = robust
scaler_scope = all
scaler_params = 0
sampler = None
feat_selector = univariate selection
feat_selector_params = 1
splits = 3
n_repeats = 2
search_type = random
search_splits = 3
search_n_iter = 50
n_jobs = 7
feats_to_use = _sst_
subjects_to_use = ('sex', 1)
compute_train_score = False
random_state = 1
calc_base_feature_importances = True
calc_shap_feature_importances = True
extra_params = {}

Saving scores and settings with unique name: light gbm0

subjects_to_use set to: sex=1,


Validation Scores
_________________
Metric:  matthews
Mean Validation score:  -0.005894966816494058
Macro Std in Validation score:  0.05764204010302601
Micro Std in Validation score:  0.07904412731728576

Metric:  macro roc auc
Mean Validation score:  0.5061562863660888
Macro Std in Validation score:  0.028332964868554605
Micro Std in Validation score:  0.04100259451047116

Metric:  balanced accuracy
Mean Validation score:  0.4967512532873981
Macro Std in Validation score:  0.02964661269998406
Micro Std in Validation score:  0.04066523340691316

Metric:  f1
Mean Validation score:  0.5054229869209405
Macro Std in Validation score:  0.16844246584739156
Micro Std in Validation score:  0.24698259219416052

