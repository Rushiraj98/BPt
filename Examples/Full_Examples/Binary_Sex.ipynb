{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook goes through a simple binary classification example, explaining general library functionality and loading along the way.\n",
    "\n",
    "We perform binary classification on sex, using structural MRI rois."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ABCD_ML import ABCD_ML, Load # These are the main library imports\n",
    "\n",
    "# The rest of these are just used to help show different things\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following definition are useful simply as a shorthand for defining long file paths all in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base data directories, 2.0 release with most of the phenotype information\n",
    "nda_dr = '/home/sage/work/ABCD2p0NDA/'\n",
    "\n",
    "# This folder contains the re-released 2.0.1 fixed MRI derived measurements\n",
    "nda_dr2 = '/home/sage/work/ABCDFixRelease2p0p1/'\n",
    "\n",
    "#This file stores the name mapping\n",
    "map_file = os.path.join(nda_dr2, 'Fix Release Notes 2.0.1_Public', '24. ABCD_Release_2.0.1_Updates',\n",
    "                        'abcd_2.0.1_mapping.csv')\n",
    "\n",
    "# Destr atlas structural MRI rois\n",
    "data1 = os.path.join(nda_dr2, 'abcd_mrisdp101.txt')\n",
    "data2 = os.path.join(nda_dr2, 'abcd_mrisdp201.txt')\n",
    "\n",
    "# Family ID\n",
    "strat1 = os.path.join(nda_dr, 'acspsw03.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to define the class object, which we will use to load load and to train/test different ML models.\n",
    "There are a few global parameters which we can optionally set when defining this object as well, lets look and see what they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module ABCD_ML.main.ABCD_ML:\n",
      "\n",
      "__init__(self, exp_name='Exp', log_dr='', existing_log='append', verbose=True, notebook=True, use_default_subject_ids=False, low_memory_mode=False, strat_u_name='_Strat', dpi=100, random_state=None)\n",
      "    Main class init\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    exp_name : str, optional\n",
      "        The name of this experimental run,\n",
      "        used explicitly in saving logs, and figures.\n",
      "        If log_dr is not set to None-\n",
      "        (if not None then saves logs and figures)\n",
      "        then a folder is created within the log dr\n",
      "        with the exp_name.\n",
      "    \n",
      "        (default = 'Exp')\n",
      "    \n",
      "    log_dr : str, Path or None, optional\n",
      "        The directory in which to store logs...\n",
      "        If set to None, then will not save any logs!\n",
      "        If set to '', will save in the current dr.\n",
      "    \n",
      "        (default = '')\n",
      "    \n",
      "    existing_log : {'new', 'append', 'overwrite'}, optional\n",
      "        By default, if an exp_name folder already\n",
      "        exists within the log_dr, then the exp_name will\n",
      "        be incremented until a free name is avaliable.\n",
      "        This behavior is existing_log is 'new',\n",
      "        If existing_log is 'append' then log entries\n",
      "        and new figures will be added to the existing folder.\n",
      "        If existing_log is 'overwrite', then the existing\n",
      "        log folder with the same exp_name will be cleared\n",
      "        upon __init__.\n",
      "    \n",
      "        (default = 'append')\n",
      "    \n",
      "    verbose: bool, optional\n",
      "        If set to true will print diagnostic and other output during\n",
      "        dataloading and model training ect... if set to False this output\n",
      "        will not print. If log_dr is not None, then will still\n",
      "        record as log output.\n",
      "    \n",
      "        (default = True)\n",
      "    \n",
      "    notebook : bool, optional\n",
      "        If True, then assumes the user is running\n",
      "        the code in an interactive notebook. In this case,\n",
      "        any plots will be showed interactively\n",
      "        (as well as saved as long as log_dr != None)\n",
      "    \n",
      "        (default = True)\n",
      "    \n",
      "    use_default_subject_ids : bool, optional\n",
      "        Flag to determine the usage of 'default' subject id behavior.\n",
      "        If set to True, this will convert input NDAR subject ids\n",
      "        into upper case, with prepended NDAR - type format.\n",
      "        If set to False, then all input subject names must be entered\n",
      "        explicitly the same, no preprocessing will be done on them.\n",
      "    \n",
      "        (default = False)\n",
      "    \n",
      "    low_memory_mode : bool, optional\n",
      "        This parameter dictates behavior around loading in data,\n",
      "        specifically, if `low_memory_mode` is set to True,\n",
      "        then when loading data from multiple sources, only common\n",
      "        subjects will be saved as each data source is loaded.\n",
      "        For comparison, when low memory mode if off, the dropping\n",
      "        of non-common subjects occurs later. Though regardless of if low\n",
      "        memory mode is on or off, subjects will be dropped right away\n",
      "        when exclusions or strat is loaded. Non-low memory mode\n",
      "        behavior is useful when the user wants to try loading different\n",
      "        data, and doesn't want automatic drops to occur.\n",
      "        If set to True, individual dataframes self.data, self.covars ect...\n",
      "        will also be deleted from memory as soon as modeling begins.\n",
      "        This parameter also controls the pandas read_csv behavior,\n",
      "        which also has a low_memory flag.\n",
      "    \n",
      "        (default = False)\n",
      "    \n",
      "    strat_u_name : str, optional\n",
      "        A unique str identifier to be appended to every loaded\n",
      "        strat value (to keep it seperate from covars and data).\n",
      "    \n",
      "        (default = '_Strat')\n",
      "    \n",
      "    dpi : int, optional\n",
      "        The default dpi in which to save any distribution or feature\n",
      "        importance plots.\n",
      "    \n",
      "        (default = 100)\n",
      "    \n",
      "    random_state : int, RandomState instance or None, optional\n",
      "        The default random state, either as int for a specific seed,\n",
      "        or if None then the random seed is set by np.random.\n",
      "        This parameters if set will be the default random_state class-wide,\n",
      "        so any place random_state is left to default, unless a different\n",
      "        default is set (e.g. default load value or default ML value) this\n",
      "        random state will be used.\n",
      "    \n",
      "        (default = None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ABCD_ML.__init__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the default parameters are okay for this simple example, but any of them can be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name = Sex\n",
      "log_dr = /home/sage/ABCD_ML/Examples/Full_Examples\n",
      "existing_log = overwrite\n",
      "verbose = True\n",
      "exp log dr setup at: /home/sage/ABCD_ML/Examples/Full_Examples/Sex\n",
      "log file at: /home/sage/ABCD_ML/Examples/Full_Examples/Sex/logs.txt\n",
      "notebook = True\n",
      "use_default_subject_ids = True\n",
      "low memory mode = False\n",
      "strat_u_name = _Strat\n",
      "random state = 1\n",
      "ABCD_ML object initialized\n"
     ]
    }
   ],
   "source": [
    "ML = ABCD_ML(exp_name = 'Sex',\n",
    "             existing_log = 'overwrite',\n",
    "             use_default_subject_ids = True,\n",
    "             random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will consider setting default parameters for loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method Set_Default_Load_Params in module ABCD_ML.main._Data:\n",
      "\n",
      "Set_Default_Load_Params(dataset_type='default', subject_id='default', eventname='default', eventname_col='default', overlap_subjects='default', na_values='default', drop_na='default', drop_or_na='default') method of ABCD_ML.main.ABCD_ML.ABCD_ML instance\n",
      "    This function is used to define default values for a series of\n",
      "    params accessible to all or most of the different loading functions.\n",
      "    By setting common values here, it reduces the need to repeat params within\n",
      "    each loader (e.g. Load_Data, Load_Targets, ect...)\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    dataset_type : {'basic', 'explorer', 'custom'}, optional\n",
      "        The dataset_type / file-type to load from.\n",
      "        Dataset types are,\n",
      "    \n",
      "        - 'basic'\n",
      "            ABCD2p0NDA style (.txt and tab seperated).\n",
      "            Typically the default columns, and therefore not neuroimaging\n",
      "            data, will be dropped, also not including the eventname column.\n",
      "    \n",
      "        - 'explorer'\n",
      "            2.0_ABCD_Data_Explorer style (.csv and comma seperated).\n",
      "            The first 2 columns before self.subject_id\n",
      "            (typically the default columns, and therefore not neuroimaging\n",
      "            data - also not including the eventname column), will be dropped.\n",
      "    \n",
      "        - 'custom'\n",
      "            A user-defined custom dataset. Right now this is only.\n",
      "            supported as a comma seperated file, with the subject names in a\n",
      "            column called self.subject_id, and can optionally have\n",
      "            'eventname'. No columns will be dropped,\n",
      "            (except eventname) or unless specific drop keys are passed.\n",
      "    \n",
      "        If loading multiple locs as a list, dataset_type can be a list with\n",
      "        inds corresponding to which datatype for each loc.\n",
      "    \n",
      "        if 'default', and not already defined, set to 'basic'\n",
      "        (default = 'default')\n",
      "    \n",
      "    subject_id : str, optional\n",
      "        The name of the column with unique subject ids in different\n",
      "        dataset, for default ABCD datasets this is 'src_subject_id',\n",
      "        but if a user wanted to load and work with a different dataset,\n",
      "        they just need to change this accordingly\n",
      "        (in addition to setting eventname most likely to None and\n",
      "        use_default_subject_ids to False)\n",
      "    \n",
      "        if 'default', and not already defined, set to 'src_subject_id'.\n",
      "        (default = 'default')\n",
      "    \n",
      "    eventname : value, list of values or None, optional\n",
      "        Optional value to provide, specifying to optional keep certain rows\n",
      "        when reading data based on the eventname flag, where eventname\n",
      "        is the value and eventname_col is the name of the value.\n",
      "    \n",
      "        If a list of values are passed, then it will be treated as keeping a\n",
      "        row if that row's value within the eventname_col is equal to ANY\n",
      "        of the passed eventname values.\n",
      "    \n",
      "        As ABCD is a longitudinal study, this flag lets you select only\n",
      "        one specific time point, or if set to None, will load everything.\n",
      "    \n",
      "        For selecting only baseline imagine data one might consider\n",
      "        setting this param to 'baseline_year_1_arm_1'.\n",
      "    \n",
      "        if 'default', and not already defined, set to None.\n",
      "        (default = 'default')\n",
      "    \n",
      "    eventname_col : str or None, optional\n",
      "        If an eventname is provided, this param refers to\n",
      "        the column name containing the eventname. This could\n",
      "        also be used along with eventname to be set to any\n",
      "        arbitrary value, in order to perform selection by specific\n",
      "        column value.\n",
      "    \n",
      "        Note: The eventname col is dropped after proc'ed!\n",
      "    \n",
      "        if 'default', and not already defined, set to 'eventname'\n",
      "        (default = 'default')\n",
      "    \n",
      "    overlap_subjects : bool, optional\n",
      "        This parameter dictates when loading data, covars, targets or strat\n",
      "        (after initial basic proc and/or merge w/ other passed loc's),\n",
      "        if the loaded data should be restricted to only the\n",
      "        overlapping subjects from previously loaded data, targets, covars\n",
      "        or strat - important when performing intermediate proc.\n",
      "        If False, then all subjects will\n",
      "        be kept throughout the rest of the optional processing - and only\n",
      "        merged at the end AFTER processing has been done.\n",
      "    \n",
      "        Note: Inclusions and Exclusions are always applied regardless of this\n",
      "        parameter.\n",
      "    \n",
      "        if 'default', and not already defined, set to False\n",
      "        (default = 'default')\n",
      "    \n",
      "    na_values : list, optional\n",
      "        Additional values to treat as NaN, by default ABCD specific\n",
      "        values of '777' and '999' are treated as NaN,\n",
      "        and those set to default by pandas 'read_csv' function.\n",
      "        Note: if new values are passed here,\n",
      "        it will override these default '777' and '999' NaN values,\n",
      "        so if it desired to keep these, they should be passed explicitly,\n",
      "        along with any new values.\n",
      "    \n",
      "        if 'default', and not already defined, set to ['777', '999']\n",
      "        (default = 'default')\n",
      "    \n",
      "    drop_na : bool, int, float or 'default', optional\n",
      "        This setting sets the value for drop_na,\n",
      "        which is used when loading data and covars only!\n",
      "    \n",
      "        If set to True, then will drop any row within the loaded\n",
      "        data if there are any NaN! If False, the will not drop any\n",
      "        rows for missing values.\n",
      "    \n",
      "        If an int or float, then this means some NaN entries\n",
      "        will potentially be preserved! Missing data imputation\n",
      "        will therefore be required later on!\n",
      "    \n",
      "        If an int > 1, then will drop any row with more than drop_na\n",
      "        NaN values. If a float, will determine the drop threshold as\n",
      "        a percentage of the possible values, where 1 would not drop any\n",
      "        rows as it would require the number of columns + 1 NaN, and .5\n",
      "        would require that more than half the column entries are NaN in\n",
      "        order to drop that row.\n",
      "    \n",
      "        if 'default', and not already defined, set to True\n",
      "        (default = 'default')\n",
      "    \n",
      "    drop_or_na : {'drop', 'na'}, optional\n",
      "    \n",
      "        This setting sets the value for drop_na,\n",
      "        which is used when loading data and covars only!\n",
      "    \n",
      "        filter_outlier_percent, or when loading a binary variable\n",
      "        in load covars and more then two classes are present - are both\n",
      "        instances where rows/subjects are by default dropped.\n",
      "        If drop_or_na is set to 'na', then these values will instead be\n",
      "        set to 'na' rather then the whole row dropped!\n",
      "    \n",
      "        Otherwise, if left as default value of 'drop', then rows will be\n",
      "        dropped!\n",
      "    \n",
      "        if 'default', and not already defined, set to 'drop'\n",
      "        (default = 'default')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ML.Set_Default_Load_Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default load params set within self.default_load_params.\n",
      "----------------------\n",
      "dataset_type: basic\n",
      "subject_id: src_subject_id\n",
      "eventname: baseline_year_1_arm_1\n",
      "eventname_col: eventname\n",
      "overlap_subjects: False\n",
      "na_values: ['777', '999']\n",
      "drop_na: True\n",
      "drop_or_na: drop\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.Set_Default_Load_Params(dataset_type = 'basic',\n",
    "                           eventname = 'baseline_year_1_arm_1',\n",
    "                           eventname_col = 'eventname',\n",
    "                           drop_na = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can continue by optionally loading in a name map, which is simply a dictionary that attempts to rename any column names loaded in, if those column names are a key in the dictionary. This is useful for ABCD data as the default column names might not be useful. This mapping was provided along with the 2.0.1 data release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/sage/work/ABCDFixRelease2p0p1/Fix Release Notes 2.0.1_Public/24. ABCD_Release_2.0.1_Updates/abcd_2.0.1_mapping.csv  with dataset type: explorer\n",
      "Loading new name_map from file!\n"
     ]
    }
   ],
   "source": [
    "ML.Load_Name_Map(loc = map_file,\n",
    "                 dataset_type = 'explorer',\n",
    "                 source_name_col = 'nda_name',\n",
    "                 target_name_col = 'deap_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at what exactly is in this dictionary if we want to confirm we loaded it correctly.\n",
    "It is loaded as name_map within the ABCD_ML class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ddtidp_119': 'dmri_dti.fa.wm_cort.destrieux_s.central.rh',\n",
       " 'ddtidp_120': 'dmri_dti.fa.wm_cort.destrieux_s.cingul.marginalis.rh',\n",
       " 'ddtidp_121': 'dmri_dti.fa.wm_cort.destrieux_s.circular.insula.ant.rh',\n",
       " 'ddtidp_122': 'dmri_dti.fa.wm_cort.destrieux_s.circular.insula.inf.rh',\n",
       " 'ddtidp_123': 'dmri_dti.fa.wm_cort.destrieux_s.circular.insula.sup.rh',\n",
       " 'ddtidp_124': 'dmri_dti.fa.wm_cort.destrieux_s.collat.transv.ant.rh',\n",
       " 'ddtidp_125': 'dmri_dti.fa.wm_cort.destrieux_s.collat.transv.post.rh',\n",
       " 'ddtidp_126': 'dmri_dti.fa.wm_cort.destrieux_s.front.inf.rh',\n",
       " 'ddtidp_127': 'dmri_dti.fa.wm_cort.destrieux_s.front.middle.rh',\n",
       " 'ddtidp_128': 'dmri_dti.fa.wm_cort.destrieux_s.front.sup.rh',\n",
       " 'ddtidp_129': 'dmri_dti.fa.wm_cort.destrieux_s.interm.prim.jensen.rh',\n",
       " 'ddtidp_130': 'dmri_dti.fa.wm_cort.destrieux_s.intrapariet.and.p.trans.rh',\n",
       " 'ddtidp_131': 'dmri_dti.fa.wm_cort.destrieux_s.oc.middle.and.lunatus.rh',\n",
       " 'ddtidp_132': 'dmri_dti.fa.wm_cort.destrieux_s.oc.sup.and.transversal.rh',\n",
       " 'ddtidp_133': 'dmri_dti.fa.wm_cort.destrieux_s.occipital.ant.rh',\n",
       " 'ddtidp_134': 'dmri_dti.fa.wm_cort.destrieux_s.oc.temp.lat.rh',\n",
       " 'ddtidp_135': 'dmri_dti.fa.wm_cort.destrieux_s.oc.temp.med.and.lingual.rh',\n",
       " 'ddtidp_136': 'dmri_dti.fa.wm_cort.destrieux_s.orbital.lateral.rh',\n",
       " 'ddtidp_137': 'dmri_dti.fa.wm_cort.destrieux_s.orbital.med.olfact.rh',\n",
       " 'ddtidp_138': 'dmri_dti.fa.wm_cort.destrieux_s.orbital.h.shaped.rh'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_examples = {k: ML.name_map[k] for k in list(ML.name_map)[300:320]}\n",
    "some_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step to consider is in if there are any subjects which should be apriori excluded. These can be defined as either a list of subjects to exclude, or as a list of subjects to include (where only those subjects that appear in the list would be kept).\n",
    "\n",
    "See:\n",
    "\n",
    "- https://abcd-ml.readthedocs.io/en/latest/ABCD_ML_class_docs.html#load-exclusions\n",
    "\n",
    "- https://abcd-ml.readthedocs.io/en/latest/ABCD_ML_class_docs.html#load-inclusions\n",
    "\n",
    "In this example we will not define any.\n",
    "\n",
    "Next, we will load in the actual data of interest. You will note when looking at the help function that all of the parameter we set in the defaults can also be set here as well, or if we want to keep the default params, we just leave the values as is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method Load_Data in module ABCD_ML.main._Data:\n",
      "\n",
      "Load_Data(loc=None, df=None, dataset_type='default', drop_keys=None, inclusion_keys=None, subject_id='default', eventname='default', eventname_col='default', overlap_subjects='default', na_values='default', drop_na='default', drop_or_na='default', filter_outlier_percent=None, filter_outlier_std=None, unique_val_drop=None, unique_val_warn=0.05, drop_col_duplicates=None, clear_existing=False) method of ABCD_ML.main.ABCD_ML.ABCD_ML instance\n",
      "    Class method for loading ROI-style data, assuming all loaded\n",
      "    columns are continuous / float datatype.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    loc : str Path, list of or None, optional\n",
      "        The location of the file to load data load from.\n",
      "        If passed a list, then will load each loc in the list,\n",
      "        and will assume them all to be of the same dataset_type if one\n",
      "        dataset_type is passed, or if they differ in type, a list must be\n",
      "        passed to dataset_type with the different types in order.\n",
      "    \n",
      "        Note: some proc will be done on each loaded dataset before merging\n",
      "        with the rest (duplicate subjects, proc for eventname ect...), but\n",
      "        other dataset loading behavior won't occur until after the merge,\n",
      "        e.g., dropping cols by key, filtering for outlier, ect...\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    df : pandas DataFrame or None, optional\n",
      "        This parameter represents the option for the user to pass in\n",
      "        a raw custom dataframe. A loc and/or a df must be passed.\n",
      "    \n",
      "        When pasing a raw DataFrame, the loc and dataset_type\n",
      "        param will be ignored, as those are for loading data from a file.\n",
      "        Otherwise, it will be treated the same as\n",
      "        if loading from a file, which means, there should be a column within\n",
      "        the passed dataframe with subject_id, and e.g. if eventname params are\n",
      "        passed, they will be applied along with any other proc. specified.\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    dataset_type : {'basic', 'explorer', 'custom'}, optional\n",
      "        The dataset_type / file-type to load from.\n",
      "        Dataset types are,\n",
      "    \n",
      "        - 'basic'\n",
      "            ABCD2p0NDA style (.txt and tab seperated).\n",
      "            Typically the default columns, and therefore not neuroimaging\n",
      "            data, will be dropped, also not including the eventname column.\n",
      "    \n",
      "        - 'explorer'\n",
      "            2.0_ABCD_Data_Explorer style (.csv and comma seperated).\n",
      "            The first 2 columns before self.subject_id\n",
      "            (typically the default columns, and therefore not neuroimaging\n",
      "            data - also not including the eventname column), will be dropped.\n",
      "    \n",
      "        - 'custom'\n",
      "            A user-defined custom dataset. Right now this is only.\n",
      "            supported as a comma seperated file, with the subject names in a\n",
      "            column called self.subject_id, and can optionally have\n",
      "            'eventname'. No columns will be dropped,\n",
      "            (except eventname) or unless specific drop keys are passed.\n",
      "    \n",
      "        If loading multiple locs as a list, dataset_type can be a list with\n",
      "        inds corresponding to which datatype for each loc.\n",
      "    \n",
      "        if 'default', and not already defined, set to 'basic'\n",
      "        (default = 'default')\n",
      "    \n",
      "    drop_keys : str, list or None, optional\n",
      "        A list of keys to drop columns by, where if any key given in a columns\n",
      "        name, then that column will be dropped. If a str, then same behavior,\n",
      "        just with one col.\n",
      "        (Note: if a name mapping exists, this drop step will be\n",
      "        conducted after renaming)\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    inclusion_keys : str, list or None, optional\n",
      "        A list of keys in which to only keep a loaded data\n",
      "        column if ANY of the passed inclusion_keys are present\n",
      "        within that column name.\n",
      "    \n",
      "        If passed only with drop_keys will be proccessed second.\n",
      "    \n",
      "        (Note: if a name mapping exists, this drop step will be\n",
      "        conducted after renaming)\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    subject_id : str, optional\n",
      "        The name of the column with unique subject ids in different\n",
      "        dataset, for default ABCD datasets this is 'src_subject_id',\n",
      "        but if a user wanted to load and work with a different dataset,\n",
      "        they just need to change this accordingly\n",
      "        (in addition to setting eventname most likely to None and\n",
      "        use_default_subject_ids to False)\n",
      "    \n",
      "        if 'default', and not already defined, set to 'src_subject_id'.\n",
      "        (default = 'default')\n",
      "    \n",
      "    eventname : value, list of values or None, optional\n",
      "        Optional value to provide, specifying to optional keep certain rows\n",
      "        when reading data based on the eventname flag, where eventname\n",
      "        is the value and eventname_col is the name of the value.\n",
      "    \n",
      "        If a list of values are passed, then it will be treated as keeping a\n",
      "        row if that row's value within the eventname_col is equal to ANY\n",
      "        of the passed eventname values.\n",
      "    \n",
      "        As ABCD is a longitudinal study, this flag lets you select only\n",
      "        one specific time point, or if set to None, will load everything.\n",
      "    \n",
      "        For selecting only baseline imagine data one might consider\n",
      "        setting this param to 'baseline_year_1_arm_1'.\n",
      "    \n",
      "        if 'default', and not already defined, set to None.\n",
      "        (default = 'default')\n",
      "    \n",
      "    eventname_col : str or None, optional\n",
      "        If an eventname is provided, this param refers to\n",
      "        the column name containing the eventname. This could\n",
      "        also be used along with eventname to be set to any\n",
      "        arbitrary value, in order to perform selection by specific\n",
      "        column value.\n",
      "    \n",
      "        Note: The eventname col is dropped after proc'ed!\n",
      "    \n",
      "        if 'default', and not already defined, set to 'eventname'\n",
      "        (default = 'default')\n",
      "    \n",
      "    overlap_subjects : bool, optional\n",
      "        This parameter dictates when loading data, covars, targets or strat\n",
      "        (after initial basic proc and/or merge w/ other passed loc's),\n",
      "        if the loaded data should be restricted to only the\n",
      "        overlapping subjects from previously loaded data, targets, covars\n",
      "        or strat - important when performing intermediate proc.\n",
      "        If False, then all subjects will\n",
      "        be kept throughout the rest of the optional processing - and only\n",
      "        merged at the end AFTER processing has been done.\n",
      "    \n",
      "        Note: Inclusions and Exclusions are always applied regardless of this\n",
      "        parameter.\n",
      "    \n",
      "        if 'default', and not already defined, set to False\n",
      "        (default = 'default')\n",
      "    \n",
      "    na_values : list, optional\n",
      "        Additional values to treat as NaN, by default ABCD specific\n",
      "        values of '777' and '999' are treated as NaN,\n",
      "        and those set to default by pandas 'read_csv' function.\n",
      "        Note: if new values are passed here,\n",
      "        it will override these default '777' and '999' NaN values,\n",
      "        so if it desired to keep these, they should be passed explicitly,\n",
      "        along with any new values.\n",
      "    \n",
      "        if 'default', and not already defined, set to ['777', '999']\n",
      "        (default = 'default')\n",
      "    \n",
      "    drop_na : bool, int, float or 'default', optional\n",
      "        This setting sets the value for drop_na,\n",
      "        which is used when loading data and covars only!\n",
      "    \n",
      "        If set to True, then will drop any row within the loaded\n",
      "        data if there are any NaN! If False, the will not drop any\n",
      "        rows for missing values.\n",
      "    \n",
      "        If an int or float, then this means some NaN entries\n",
      "        will potentially be preserved! Missing data imputation\n",
      "        will therefore be required later on!\n",
      "    \n",
      "        If an int > 1, then will drop any row with more than drop_na\n",
      "        NaN values. If a float, will determine the drop threshold as\n",
      "        a percentage of the possible values, where 1 would not drop any\n",
      "        rows as it would require the number of columns + 1 NaN, and .5\n",
      "        would require that more than half the column entries are NaN in\n",
      "        order to drop that row.\n",
      "    \n",
      "        if 'default', and not already defined, set to True\n",
      "        (default = 'default')\n",
      "    \n",
      "    drop_or_na : {'drop', 'na'}, optional\n",
      "    \n",
      "        This setting sets the value for drop_na,\n",
      "        which is used when loading data and covars only!\n",
      "    \n",
      "        filter_outlier_percent, or when loading a binary variable\n",
      "        in load covars and more then two classes are present - are both\n",
      "        instances where rows/subjects are by default dropped.\n",
      "        If drop_or_na is set to 'na', then these values will instead be\n",
      "        set to 'na' rather then the whole row dropped!\n",
      "    \n",
      "        Otherwise, if left as default value of 'drop', then rows will be\n",
      "        dropped!\n",
      "    \n",
      "        if 'default', and not already defined, set to 'drop'\n",
      "        (default = 'default')\n",
      "    \n",
      "    filter_outlier_percent : int, float, tuple or None, optional\n",
      "        *For float data only.*\n",
      "        A percent of values to exclude from either end of the\n",
      "        targets distribution, provided as either 1 number,\n",
      "        or a tuple (% from lower, % from higher).\n",
      "        set `filter_outlier_percent` to None for no filtering.\n",
      "        If over 1 then treated as a percent, if under 1, then\n",
      "        used directly.\n",
      "    \n",
      "        If drop_or_na == 'drop', then all rows/subjects with >= 1\n",
      "        value(s) found outside of the percent will be dropped.\n",
      "        Otherwise, if drop_or_na = 'na', then any outside values\n",
      "        will be set to NaN.\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    filter_outlier_std : int, float, tuple or None, optional\n",
      "        *For float data only.*\n",
      "        Determines outliers as data points within each column where their\n",
      "        value is less than the mean of the column - `filter_outlier_std[0]`\n",
      "        * the standard deviation of the column,\n",
      "        and greater than the mean of the column + `filter_outlier_std[1]`\n",
      "        * the standard deviation of the column.\n",
      "    \n",
      "        If a singler number is passed, that number is applied to both the lower\n",
      "        and upper range. If a tuple with None on one side is passed, e.g.\n",
      "        (None, 3), then nothing will be taken off that lower or upper bound.\n",
      "    \n",
      "        If drop_or_na == 'drop', then all rows/subjects with >= 1\n",
      "        value(s) found will be dropped. Otherwise, if drop_or_na = 'na',\n",
      "        then any outside values will be set to NaN.\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    unique_val_drop : int, float None, optional\n",
      "        This parameter allows you to drops columns within loaded data\n",
      "        where there are under a certain threshold of unique values.\n",
      "    \n",
      "        The threshold is determined by the passed value as either a float for \n",
      "        a percentage of the data, e.g., computed as unique_val_drop * len(data), \n",
      "        or if passed a number greater then 1, then that number, where a\n",
      "        ny column with less unique values then this threshold will be dropped.\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    unique_val_warn : int or float, optional\n",
      "        This parameter is simmilar to unique_val_drop, but only\n",
      "        warns about columns with under the threshold (see unique_val_drop for\n",
      "        how the threshold is computed) unique vals.\n",
      "    \n",
      "        (default = .05)\n",
      "    \n",
      "    drop_col_duplicates : float or None/False, optional\n",
      "        If set to None, will not drop any.\n",
      "        If float, then pass a value between 0 and 1,\n",
      "        where if two columns within data\n",
      "        are correlated >= to `corr_thresh`, the second column is removed.\n",
      "    \n",
      "        A value of 1 will instead make a quicker direct =='s comparison.\n",
      "    \n",
      "        Note: This param just drops duplicated within the just loaded data.\n",
      "        You can call self.Drop_Data_Duplicates() to drop duplicates across\n",
      "        all loaded data.\n",
      "    \n",
      "        Be advised, this functionality runs rather slow when there are ~500+\n",
      "        columns to compare!\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    clear_existing : bool, optional\n",
      "        If this parameter is set to True, then any existing\n",
      "        loaded data will first be cleared before loading new data!\n",
      "    \n",
      "        .. WARNING::\n",
      "            If any subjects have been dropped from a different place,\n",
      "            e.g. targets, then simply reloading / clearing existing data\n",
      "            might result in computing a misleading overlap of final\n",
      "            valid subjects. Reloading should therefore be best used\n",
      "            right after loading the original data, or if not possible,\n",
      "            then reloading the notebook or re-running the script.\n",
      "    \n",
      "        (default = False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ML.Load_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/sage/work/ABCDFixRelease2p0p1/abcd_mrisdp101.txt  with dataset type: basic\n",
      "dropped ['collection_id', 'abcd_mrisdp101_id', 'dataset_id', 'subjectkey', 'interview_age', 'interview_date', 'sex', 'collection_title', 'study_cohort_name'] columns by default  due to dataset type\n",
      "\n",
      "Loading /home/sage/work/ABCDFixRelease2p0p1/abcd_mrisdp201.txt  with dataset type: basic\n",
      "dropped ['collection_id', 'abcd_mrisdp201_id', 'dataset_id', 'subjectkey', 'interview_age', 'interview_date', 'sex', 'collection_title', 'study_cohort_name'] columns by default  due to dataset type\n",
      "\n",
      "Dropped 0 cols for all missing values\n",
      "Dropped 2892 rows for missing values, based on the provided drop_na param: True with actual na_thresh: 0\n",
      "Loaded rows with NaN remaining: 0\n",
      "\n",
      "Processing unique col values with drop threshold: 0 - warn threshold: 432.1 - out of 8642 rows\n",
      "Warn - smri_area_cort.destrieux_g.front.inf.orbital.lh has unique vals: 300\n",
      "Warn - smri_area_cort.destrieux_g.ins.lg.and.s.cent.ins.lh has unique vals: 350\n",
      "Warn - smri_area_cort.destrieux_g.temp.sup.g.t.transv.lh has unique vals: 417\n",
      "Warn - smri_area_cort.destrieux_lat.fis.ant.horizont.lh has unique vals: 300\n",
      "Warn - smri_area_cort.destrieux_lat.fis.ant.vertical.lh has unique vals: 395\n",
      "Warn - smri_area_cort.destrieux_s.circular.insula.ant.lh has unique vals: 398\n",
      "Warn - smri_area_cort.destrieux_s.collat.transv.post.lh has unique vals: 427\n",
      "Warn - smri_area_cort.destrieux_s.orbital.lateral.lh has unique vals: 407\n",
      "Warn - smri_area_cort.destrieux_s.temporal.transverse.lh has unique vals: 371\n",
      "Warn - smri_area_cort.destrieux_g.cingul.post.ventral.rh has unique vals: 302\n",
      "Warn - smri_area_cort.destrieux_g.front.inf.orbital.rh has unique vals: 351\n",
      "Warn - smri_area_cort.destrieux_g.ins.lg.and.s.cent.ins.rh has unique vals: 355\n",
      "Warn - smri_area_cort.destrieux_g.rectus.rh has unique vals: 399\n",
      "Warn - smri_area_cort.destrieux_g.temp.sup.g.t.transv.rh has unique vals: 321\n",
      "Warn - smri_area_cort.destrieux_lat.fis.ant.horizont.rh has unique vals: 361\n",
      "Warn - smri_area_cort.destrieux_lat.fis.ant.vertical.rh has unique vals: 328\n",
      "Warn - smri_area_cort.destrieux_s.temporal.transverse.rh has unique vals: 290\n",
      "\n",
      "loaded shape:  (8642, 1510)\n",
      "\n",
      "Total valid overlapping subjects = 8642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.Load_Data(loc = [data1, data2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the loading data function has warned us about some columns with a suspiciously low number of unique values, and also note that they are all surface area, so maybe that is expected. Lets turn warn off in the future\n",
    "\n",
    "The other alarming thing to note is we are losing 2892 rows for missing values. One way we can examine this further is to re-load the data, but without dropping any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Load_Data(loc = [data1, data2],\n",
    "             unique_val_warn = None,\n",
    "             drop_na = False,\n",
    "             clear_existing = True # Make sure to call clear_existing if re-loading the same data!\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are provided some more detailed information about what NaN columns are loaded. This is useful because we can note there are 435 columns found with 617 missing values, and of those 435 columns, 'smri_t2w.' is one of the keys present in all of them. In this case, what we can do is try not loading t2w rois, as it is clear some number of subjects just didn't get a t2 scan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Load_Data(loc = [data1, data2],\n",
    "             unique_val_warn = None,\n",
    "             drop_keys = 'smri_t2w.',\n",
    "             drop_na = False,\n",
    "             clear_existing = True\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a few different options for how we want to handle the rest of the NaN's. The first is to either just drop all of them, but as evident by 437 columns found with 4 missing values, it might be the case that there are just a few subjects with a messed up scan, and therefore a bunch of NaN's. We can try setting drop_nan to 10. In that case, only subjects with less then or equal to 10 NaNs will be kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Load_Data(loc = [data1, data2],\n",
    "             unique_val_warn = None,\n",
    "             drop_keys = 'smri_t2w.',\n",
    "             drop_na = 10,\n",
    "             clear_existing = True\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay great. Now we have 2384 subjects with atleast one NaN value to impute, but we know that all of those subjects only have 1-10 missing values, and likewise, no single feature seems to have all that many NaN's. We now have 11522 subjects and still 1057 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the data distribution visually too for a few random ROIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML.Show_Data_Dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does not appear to be too many big outliers in the dataset (some, but...), lets avoid doing any outlier dropping in this example, and instead if it is a problem deal with it during modelling. In general, there are a number of methods for dropping outliers or performing other proc on the loaded data either built into Load_Data or as an external function, e.g., Proc_Data_Unique_Cols https://abcd-ml.readthedocs.io/en/latest/ABCD_ML_class_docs.html#proc-data-unique-cols\n",
    "\n",
    "We will load our target variable next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method Load_Targets in module ABCD_ML.main._Data:\n",
      "\n",
      "Load_Targets(loc=None, df=None, col_name=None, data_type=None, dataset_type='default', subject_id='default', eventname='default', eventname_col='default', overlap_subjects='default', filter_outlier_percent=None, filter_outlier_std=None, categorical_drop_percent=None, na_values='default', clear_existing=False) method of ABCD_ML.main.ABCD_ML.ABCD_ML instance\n",
      "    Loads in targets, the outcome / variable(s) to predict.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    loc : str, Path or None, optional\n",
      "        The location of the file to load targets load from.\n",
      "    \n",
      "        Either loc or df must be set, but they both cannot be set!\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    df : pandas DataFrame or None, optional\n",
      "        This parameter represents the option for the user to pass in\n",
      "        a raw custom dataframe. A loc and/or a df must be passed.\n",
      "    \n",
      "        When pasing a raw DataFrame, the loc and dataset_type\n",
      "        param will be ignored, as those are for loading from a file.\n",
      "        Otherwise, it will be treated the same as\n",
      "        if loading from a file, which means, there should be a column within\n",
      "        the passed dataframe with subject_id, and e.g. if eventname params are\n",
      "        passed, they will be applied along with any other proc. specified.\n",
      "    \n",
      "        Either loc or df must be set, but they both cannot be set!\n",
      "    \n",
      "    col_name : str, list, optional\n",
      "        The name(s) of the column(s) to load.\n",
      "    \n",
      "        Note: Must be in the same order as data types passed in.\n",
      "        (default = None)\n",
      "    \n",
      "    data_type : {'b', 'c', 'm', 'o', 'f'}, optional\n",
      "        The data types of the different columns to load,\n",
      "        in the same order as the column names passed in.\n",
      "        Shorthands for datatypes can be used as well.\n",
      "    \n",
      "        - 'binary' or 'b'\n",
      "            Binary input\n",
      "    \n",
      "        - 'categorical' or 'c'\n",
      "            Categorical input\n",
      "    \n",
      "        - 'multilabel' or 'm'\n",
      "            Multilabel categorical input\n",
      "    \n",
      "        - 'float' or 'f'\n",
      "            Float numerical input\n",
      "    \n",
      "        .. WARNING::\n",
      "            If 'multilabel' datatype is specified, then the associated col name\n",
      "            should be a list of columns, and will be assumed to be.\n",
      "            For example, if loading multiple targets and one is multilabel,\n",
      "            a nested list should be passed to col_name.\n",
      "    \n",
      "        Datatypes are explained further in Notes.\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    dataset_type : {'basic', 'explorer', 'custom'}, optional\n",
      "        The dataset_type / file-type to load from.\n",
      "        Dataset types are,\n",
      "    \n",
      "        - 'basic'\n",
      "            ABCD2p0NDA style (.txt and tab seperated).\n",
      "            Typically the default columns, and therefore not neuroimaging\n",
      "            data, will be dropped, also not including the eventname column.\n",
      "    \n",
      "        - 'explorer'\n",
      "            2.0_ABCD_Data_Explorer style (.csv and comma seperated).\n",
      "            The first 2 columns before self.subject_id\n",
      "            (typically the default columns, and therefore not neuroimaging\n",
      "            data - also not including the eventname column), will be dropped.\n",
      "    \n",
      "        - 'custom'\n",
      "            A user-defined custom dataset. Right now this is only.\n",
      "            supported as a comma seperated file, with the subject names in a\n",
      "            column called self.subject_id, and can optionally have\n",
      "            'eventname'. No columns will be dropped,\n",
      "            (except eventname) or unless specific drop keys are passed.\n",
      "    \n",
      "        If loading multiple locs as a list, dataset_type can be a list with\n",
      "        inds corresponding to which datatype for each loc.\n",
      "    \n",
      "        if 'default', and not already defined, set to 'basic'\n",
      "        (default = 'default')\n",
      "    \n",
      "    subject_id : str, optional\n",
      "        The name of the column with unique subject ids in different\n",
      "        dataset, for default ABCD datasets this is 'src_subject_id',\n",
      "        but if a user wanted to load and work with a different dataset,\n",
      "        they just need to change this accordingly\n",
      "        (in addition to setting eventname most likely to None and\n",
      "        use_default_subject_ids to False)\n",
      "    \n",
      "        if 'default', and not already defined, set to 'src_subject_id'.\n",
      "        (default = 'default')\n",
      "    \n",
      "    eventname : value, list of values or None, optional\n",
      "        Optional value to provide, specifying to optional keep certain rows\n",
      "        when reading data based on the eventname flag, where eventname\n",
      "        is the value and eventname_col is the name of the value.\n",
      "    \n",
      "        If a list of values are passed, then it will be treated as keeping a\n",
      "        row if that row's value within the eventname_col is equal to ANY\n",
      "        of the passed eventname values.\n",
      "    \n",
      "        As ABCD is a longitudinal study, this flag lets you select only\n",
      "        one specific time point, or if set to None, will load everything.\n",
      "    \n",
      "        For selecting only baseline imagine data one might consider\n",
      "        setting this param to 'baseline_year_1_arm_1'.\n",
      "    \n",
      "        if 'default', and not already defined, set to None.\n",
      "        (default = 'default')\n",
      "    \n",
      "    eventname_col : str or None, optional\n",
      "        If an eventname is provided, this param refers to\n",
      "        the column name containing the eventname. This could\n",
      "        also be used along with eventname to be set to any\n",
      "        arbitrary value, in order to perform selection by specific\n",
      "        column value.\n",
      "    \n",
      "        Note: The eventname col is dropped after proc'ed!\n",
      "    \n",
      "        if 'default', and not already defined, set to 'eventname'\n",
      "        (default = 'default')\n",
      "    \n",
      "    overlap_subjects : bool, optional\n",
      "        This parameter dictates when loading data, covars, targets or strat\n",
      "        (after initial basic proc and/or merge w/ other passed loc's),\n",
      "        if the loaded data should be restricted to only the\n",
      "        overlapping subjects from previously loaded data, targets, covars\n",
      "        or strat - important when performing intermediate proc.\n",
      "        If False, then all subjects will\n",
      "        be kept throughout the rest of the optional processing - and only\n",
      "        merged at the end AFTER processing has been done.\n",
      "    \n",
      "        Note: Inclusions and Exclusions are always applied regardless of this\n",
      "        parameter.\n",
      "    \n",
      "        if 'default', and not already defined, set to False\n",
      "        (default = 'default')\n",
      "    \n",
      "    filter_outlier_percent : float, tuple, list of or None, optional\n",
      "        For float datatypes only.\n",
      "        A percent of values to exclude from either end of the\n",
      "        target distribution, provided as either 1 number,\n",
      "        or a tuple (% from lower, % from higher).\n",
      "        set `filter_outlier_percent` to None for no filtering.\n",
      "    \n",
      "        A list of values can also be passed in the case that\n",
      "        multiple col_names / targets are being loaded. In this\n",
      "        case, the index should correspond. If a list is not passed\n",
      "        then the same value is used for all targets.\n",
      "    \n",
      "        (default = None).\n",
      "    \n",
      "    filter_outlier_std : int, float, tuple, None or list of, optional\n",
      "        For float datatypes only.\n",
      "        Determines outliers as data points within each column\n",
      "        (target distribution) where their\n",
      "        value is less than the mean of the column - `filter_outlier_std[0]`\n",
      "        * the standard deviation of the column,\n",
      "        and greater than the mean of the column + `filter_outlier_std[1]`\n",
      "        * the standard deviation of the column.\n",
      "    \n",
      "        If a single number is passed, that number is applied to both the lower\n",
      "        and upper range.  If a tuple with None on one side is passed, e.g.\n",
      "        (None, 3), then nothing will be taken off that lower or upper bound.\n",
      "    \n",
      "        A list of values can also be passed in the case that\n",
      "        multiple col_names / covars are being loaded. In this\n",
      "        case, the index should correspond. If a list is not passed\n",
      "        here, then the same value is used when loading all targets.\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    categorical_drop_percent: float, list of or None, optional\n",
      "        Optional percentage threshold for dropping categories when\n",
      "        loading categorical data. If a float is given, then a category\n",
      "        will be dropped if it makes up less than that % of the data points.\n",
      "        E.g. if .01 is passed, then any datapoints with a category with less\n",
      "        then 1% of total valid datapoints is dropped.\n",
      "    \n",
      "        A list of values can also be passed in the case that\n",
      "        multiple col_names / targets are being loaded. In this\n",
      "        case, the index should correspond. If a list is not passed\n",
      "        then the same value is used for all targets.\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    na_values : list, optional\n",
      "        Additional values to treat as NaN, by default ABCD specific\n",
      "        values of '777' and '999' are treated as NaN,\n",
      "        and those set to default by pandas 'read_csv' function.\n",
      "        Note: if new values are passed here,\n",
      "        it will override these default '777' and '999' NaN values,\n",
      "        so if it desired to keep these, they should be passed explicitly,\n",
      "        along with any new values.\n",
      "    \n",
      "        if 'default', and not already defined, set to ['777', '999']\n",
      "        (default = 'default')\n",
      "    \n",
      "    clear_existing : bool, optional\n",
      "        If this parameter is set to True, then any existing\n",
      "        loaded targets will first be cleared before loading new targets!\n",
      "    \n",
      "        .. WARNING::\n",
      "            If any subjects have been dropped from a different place,\n",
      "            e.g. covars or data, then simply reloading / clearing existing\n",
      "            covars might result in computing a misleading overlap of final\n",
      "            valid subjects. Reloading should therefore be best used\n",
      "            right after loading the original data, or if not possible,\n",
      "            then reloading the notebook or re-running the script.\n",
      "    \n",
      "        (default = False)\n",
      "    \n",
      "    Notes\n",
      "    ----------\n",
      "    Targets can be either 'binary', 'categorical', 'multilabel',\n",
      "    or 'float',\n",
      "    \n",
      "    - binary\n",
      "        Targets are read in and label encoded to be 0 or 1,\n",
      "        Will also work if passed column of unique string also,\n",
      "        e.g. 'M' and 'F'.\n",
      "    \n",
      "    - categorical\n",
      "        Targets are treated as taking on one fixed value from a\n",
      "        limited set of possible values.\n",
      "    \n",
      "    - multilabel\n",
      "        Simmilar to categorical, but targets can take on multiple\n",
      "        values, and therefore cannot be reduced to an ordinal representation.\n",
      "    \n",
      "    - float\n",
      "        Targets are read in as a floating point number,\n",
      "        and optionally then filtered.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ML.Load_Targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, a number of the default load params are accesible when loading targets too in case they need to change. We again need to only use fairly simple functionality here, loading in the sex column from our structural mris (as some bugs with sex were fixed in release 2.0.1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/sage/work/ABCDFixRelease2p0p1/abcd_mrisdp101.txt  with dataset type: basic\n",
      "Dropped 0 cols for all missing values\n",
      "Dropped 1 rows for missing values, based on the provided drop_na param: True with actual na_thresh: 0\n",
      "Loaded rows with NaN remaining: 0\n",
      "\n",
      "loading: sex\n",
      "\n",
      "Final shape:  (11533, 1)\n",
      "\n",
      "Total valid overlapping subjects = 11521\n",
      "\n",
      "All loaded targets\n",
      "0 : sex\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.Load_Targets(loc=data1,\n",
    "                col_name='sex',\n",
    "                data_type='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set to overlapping loaded subjects.\n",
      "-- sex --\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Name</th>\n",
       "      <th>Counts</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Internal Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>5483</td>\n",
       "      <td>0.475914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>6038</td>\n",
       "      <td>0.524086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Original Name  Counts  Frequency\n",
       "Internal Name                                 \n",
       "0                         F    5483   0.475914\n",
       "1                         M    6038   0.524086"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ML.Show_Targets_Dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note when plotting the Show_Targets_Dist is the printed \"Set to overlapping loaded subjects.\", which means we are only seeing the targets distribution based on the overlap of all subjects currently loaded (so right now that is just the overlap with data). This can be set off in the case we want to see, in this case, the few subjects who will be eventually lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look into adding covars next. Where co-variates arn't quite treated as typical co-variates, but are values we would like to be able to pass as additional input to the ML model if desired (and input that can be treated with special care). This example will actually skip this step though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will considering loading different stratification values. These are the values that we can optionally define custom validation / split behavior on. Within this example, we are just going to make sure that all splits preserve subjects with the same family id within the same fold, so lets load family id - after looking as the help function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method Load_Strat in module ABCD_ML.main._Data:\n",
      "\n",
      "Load_Strat(loc=None, df=None, col_name=None, dataset_type='default', subject_id='default', eventname='default', eventname_col='default', overlap_subjects='default', binary_col=False, float_col=False, float_bins=10, float_bin_strategy='uniform', categorical_drop_percent=None, na_values='default', clear_existing=False) method of ABCD_ML.main.ABCD_ML.ABCD_ML instance\n",
      "    Load stratification values from a file.\n",
      "    See Notes for more details on what stratification values are.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    loc : str, Path or None, optional\n",
      "        The location of the file to load stratification vals load from.\n",
      "    \n",
      "        Either loc or df must be set, but they both cannot be set!\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    df : pandas DataFrame or None, optional\n",
      "        This parameter represents the option for the user to pass in\n",
      "        a raw custom dataframe. A loc and/or a df must be passed.\n",
      "    \n",
      "        When pasing a raw DataFrame, the loc and dataset_type\n",
      "        param will be ignored, as those are for loading from a file.\n",
      "        Otherwise, it will be treated the same as\n",
      "        if loading from a file, which means, there should be a column within\n",
      "        the passed dataframe with subject_id, and e.g. if eventname params are\n",
      "        passed, they will be applied along with any other proc. specified.\n",
      "    \n",
      "        Either loc or df must be set, but they both cannot be set!\n",
      "    \n",
      "    col_name : str or list, optional\n",
      "        The name(s) of the column(s) to load. Any datatype can be\n",
      "        loaded with the exception of multilabel, but for float variables\n",
      "        in particular, they should be specified with the `float_col` and\n",
      "        corresponding `float_bins` and `float_bin_strategy` params. Noisy\n",
      "        binary cols can also be specified with the `binary_col` param.\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    dataset_type : {'basic', 'explorer', 'custom'}, optional\n",
      "        The dataset_type / file-type to load from.\n",
      "        Dataset types are,\n",
      "    \n",
      "        - 'basic'\n",
      "            ABCD2p0NDA style (.txt and tab seperated).\n",
      "            Typically the default columns, and therefore not neuroimaging\n",
      "            data, will be dropped, also not including the eventname column.\n",
      "    \n",
      "        - 'explorer'\n",
      "            2.0_ABCD_Data_Explorer style (.csv and comma seperated).\n",
      "            The first 2 columns before self.subject_id\n",
      "            (typically the default columns, and therefore not neuroimaging\n",
      "            data - also not including the eventname column), will be dropped.\n",
      "    \n",
      "        - 'custom'\n",
      "            A user-defined custom dataset. Right now this is only.\n",
      "            supported as a comma seperated file, with the subject names in a\n",
      "            column called self.subject_id, and can optionally have\n",
      "            'eventname'. No columns will be dropped,\n",
      "            (except eventname) or unless specific drop keys are passed.\n",
      "    \n",
      "        If loading multiple locs as a list, dataset_type can be a list with\n",
      "        inds corresponding to which datatype for each loc.\n",
      "    \n",
      "        if 'default', and not already defined, set to 'basic'\n",
      "        (default = 'default')\n",
      "    \n",
      "    subject_id : str, optional\n",
      "        The name of the column with unique subject ids in different\n",
      "        dataset, for default ABCD datasets this is 'src_subject_id',\n",
      "        but if a user wanted to load and work with a different dataset,\n",
      "        they just need to change this accordingly\n",
      "        (in addition to setting eventname most likely to None and\n",
      "        use_default_subject_ids to False)\n",
      "    \n",
      "        if 'default', and not already defined, set to 'src_subject_id'.\n",
      "        (default = 'default')\n",
      "    \n",
      "    eventname : value, list of values or None, optional\n",
      "        Optional value to provide, specifying to optional keep certain rows\n",
      "        when reading data based on the eventname flag, where eventname\n",
      "        is the value and eventname_col is the name of the value.\n",
      "    \n",
      "        If a list of values are passed, then it will be treated as keeping a\n",
      "        row if that row's value within the eventname_col is equal to ANY\n",
      "        of the passed eventname values.\n",
      "    \n",
      "        As ABCD is a longitudinal study, this flag lets you select only\n",
      "        one specific time point, or if set to None, will load everything.\n",
      "    \n",
      "        For selecting only baseline imagine data one might consider\n",
      "        setting this param to 'baseline_year_1_arm_1'.\n",
      "    \n",
      "        if 'default', and not already defined, set to None.\n",
      "        (default = 'default')\n",
      "    \n",
      "    eventname_col : str or None, optional\n",
      "        If an eventname is provided, this param refers to\n",
      "        the column name containing the eventname. This could\n",
      "        also be used along with eventname to be set to any\n",
      "        arbitrary value, in order to perform selection by specific\n",
      "        column value.\n",
      "    \n",
      "        Note: The eventname col is dropped after proc'ed!\n",
      "    \n",
      "        if 'default', and not already defined, set to 'eventname'\n",
      "        (default = 'default')\n",
      "    \n",
      "    overlap_subjects : bool, optional\n",
      "        This parameter dictates when loading data, covars, targets or strat\n",
      "        (after initial basic proc and/or merge w/ other passed loc's),\n",
      "        if the loaded data should be restricted to only the\n",
      "        overlapping subjects from previously loaded data, targets, covars\n",
      "        or strat - important when performing intermediate proc.\n",
      "        If False, then all subjects will\n",
      "        be kept throughout the rest of the optional processing - and only\n",
      "        merged at the end AFTER processing has been done.\n",
      "    \n",
      "        Note: Inclusions and Exclusions are always applied regardless of this\n",
      "        parameter.\n",
      "    \n",
      "        if 'default', and not already defined, set to False\n",
      "        (default = 'default')\n",
      "    \n",
      "    binary_col : bool or list of, optional\n",
      "        Strat values are loaded as ordinal categorical, but there still\n",
      "        exists the case where the user would like to load a binary set of\n",
      "        values, and would like to ensure they are binary (filtering out\n",
      "        all values but the top 2 most frequent).\n",
      "    \n",
      "        This input should either be one boolean True False value,\n",
      "        or a list of values corresponding the the length of col_name if\n",
      "        col_name is a list.\n",
      "    \n",
      "        If col_name is a list and only one value for binary_col is\n",
      "        passed, then that value is applied to all loaded cols.\n",
      "    \n",
      "        (default = False)\n",
      "    \n",
      "    float_col : int, list or None, optional\n",
      "        Strat values are loaded as ordinal categorical, but one\n",
      "        could also want to load a float value, and bin it into according\n",
      "        to some strategy into ordinal categorical.\n",
      "    \n",
      "        This input should either be one boolean True False value,\n",
      "        or a list of values corresponding the the length of col_name if\n",
      "        col_name is a list.\n",
      "    \n",
      "        If col_name is a list and only one value for binary_col is\n",
      "        passed, then that value is applied to all loaded cols.\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    float_bins : int or list of, optional\n",
      "        If any float_col are set to True, then the float\n",
      "        input must be discretized into bins. This param controls\n",
      "        the number of bins to create. As with float_col, if one value\n",
      "        is passed, it is applied to all columns, but if different values\n",
      "        per column loaded are desired, a list of ints (with inds correponding)\n",
      "        should be pased.\n",
      "    \n",
      "        (default = 10)\n",
      "    \n",
      "    float_bin_strategy : {'uniform', 'quantile', 'kmeans'}, optional\n",
      "        If any float_col are set to True, then the float\n",
      "        input must be discretized into bins. This param controls\n",
      "        the strategy used to define the bins. Options are,\n",
      "    \n",
      "        - 'uniform'\n",
      "            All bins in each feature have identical widths.\n",
      "    \n",
      "        - 'quantile'\n",
      "            All bins in each feature have the same number of points.\n",
      "    \n",
      "        - 'kmeans'\n",
      "            Values in each bin have the same nearest center of a 1D\n",
      "            k-means cluster.\n",
      "    \n",
      "        As with float_col and float_bins, if one value\n",
      "        is passed, it is applied to all columns, but if different values\n",
      "        per column loaded are desired, a list of choices\n",
      "        (with inds correponding) should be pased.\n",
      "    \n",
      "        (default = 'uniform')\n",
      "    \n",
      "    categorical_drop_percent: float, None or list of, optional\n",
      "        Optional percentage threshold for dropping categories when\n",
      "        loading categorical data (so for strat these are any column that are\n",
      "        not specified as float or binary). If a float is given, then a category\n",
      "        will be dropped if it makes up less than that % of the data points.\n",
      "        E.g. if .01 is passed, then any datapoints with a category with less\n",
      "        then 1% of total valid datapoints is dropped.\n",
      "    \n",
      "        A list of values can also be passed in the case that\n",
      "        multiple col_names / strat vals are being loaded. In this\n",
      "        case, the indices should correspond. If a list is not passed\n",
      "        here, then the same value is used when loading all non float non binary\n",
      "        strat cols.\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    na_values : list, optional\n",
      "        Additional values to treat as NaN, by default ABCD specific\n",
      "        values of '777' and '999' are treated as NaN,\n",
      "        and those set to default by pandas 'read_csv' function.\n",
      "        Note: if new values are passed here,\n",
      "        it will override these default '777' and '999' NaN values,\n",
      "        so if it desired to keep these, they should be passed explicitly,\n",
      "        along with any new values.\n",
      "    \n",
      "        if 'default', and not already defined, set to ['777', '999']\n",
      "        (default = 'default')\n",
      "    \n",
      "    clear_existing : bool, optional\n",
      "        If this parameter is set to True, then any existing\n",
      "        loaded strat will first be cleared before loading new strat!\n",
      "    \n",
      "        .. WARNING::\n",
      "            If any subjects have been dropped from a different place,\n",
      "            e.g. targets or data, then simply reloading / clearing existing\n",
      "            strat might result in computing a misleading overlap of final\n",
      "            valid subjects. Reloading should therefore be best used\n",
      "            right after loading the original strat, or if not possible,\n",
      "            then reloading the notebook or re-running the script.\n",
      "    \n",
      "        (default = False)\n",
      "    \n",
      "    Notes\n",
      "    ----------\n",
      "    Stratification values are categorical variables which are loaded for the\n",
      "    purpose of defining custom validation behavior.\n",
      "    \n",
      "    For example: Sex might be loaded here, and used later to ensure\n",
      "    that any validation splits retain the same distribution of each sex.\n",
      "    See :func:`Define_Validation_Strategy`, and some arguments within\n",
      "    :func:`Evaluate` (sample_on and subjects_to_use).\n",
      "    \n",
      "    For most relaible split behavior based off strat values, make sure to load\n",
      "    strat values after data, targets and covars.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ML.Load_Strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/sage/work/ABCD2p0NDA/acspsw03.txt  with dataset type: basic\n",
      "Dropped 0 cols for all missing values\n",
      "Dropped 2 rows for missing values, based on the provided drop_na param: True with actual na_thresh: 0\n",
      "Loaded rows with NaN remaining: 0\n",
      "\n",
      "Total valid overlapping subjects = 11519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.Load_Strat(loc=strat1,\n",
    "              col_name='rel_family_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we now have all the data we will need loaded (Noting that the minimum requiriments for running an ML expiriment are just data or covars and targets, the rest being optional). The actual length of the script is also not as terrible as it seems, and once loading behavior is confirmed, verbose can even be turned off. In practice also, there is no reason why the user should not just keep reloading data, with changes to params, within the same cell by re-running it - which would defeat the point of a tutorial, but would greatly help readability!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets move onto defining our validation stratagy (which is again optional, but as stated before for this example we are going to preserve family ids within the same folds), if no explicit validation strategy is defined, then random splits will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method Define_Validation_Strategy in module ABCD_ML.main._Validation:\n",
      "\n",
      "Define_Validation_Strategy(groups=None, stratify=None, train_only_loc=None, train_only_subjects=None, show=True, show_original=True) method of ABCD_ML.main.ABCD_ML.ABCD_ML instance\n",
      "    Define a validation strategy to be used during different train/test\n",
      "    splits, in addition to model selection and model hyperparameter CV.\n",
      "    See Notes for more info.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    groups : str, list or None, optional\n",
      "        In the case of str input, will assume the str to refer\n",
      "        to a column key within the loaded strat data,\n",
      "        and will assign it as a value to preserve groups by\n",
      "        during any train/test or K-fold splits.\n",
      "        If a list is passed, then each element should be a str,\n",
      "        and they will be combined into all unique\n",
      "        combinations of the elements of the list.\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    stratify : str, list or None, optional\n",
      "        In the case of str input, will assume the str to refer\n",
      "        to a column key within the loaded strat data, or a loaded target col.,\n",
      "        and will assign it as a value to preserve\n",
      "        distribution of groups by during any train/test or K-fold splits.\n",
      "        If a list is passed, then each element should be a str,\n",
      "        and they will be combined into all unique combinations of\n",
      "        the elements of the list.\n",
      "    \n",
      "        Any target_cols passed must be categorical or binary, and cannot be\n",
      "        float/multilabel.\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    train_only_loc : str, Path or None, optional\n",
      "        Location of a file to load in train_only subjects,\n",
      "        where any subject loaded as train_only will be assigned to\n",
      "        every training fold, and never to a testing fold.\n",
      "        This file should be formatted as one subject per line.\n",
      "    \n",
      "        You can load from a loc and pass subjects, the subjects\n",
      "        from each source will be merged.\n",
      "    \n",
      "        This parameter is compatible with groups / stratify.\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    train_only_subjects : set, array-like, 'nan', or None, optional\n",
      "        An explicit list or array-like of train_only subjects, where\n",
      "        any subject loaded as train_only will be assigned to every training\n",
      "        fold, and never to a testing fold.\n",
      "    \n",
      "        You can also optionally specify 'nan' as input, which\n",
      "        will add all subjects with any NaN data to train only.\n",
      "    \n",
      "        If you want to add both all the NaN subjects and custom\n",
      "        subjects, call :func:`Get_Nan_Subjects` to get all NaN subjects,\n",
      "        and then merge them yourself with any you want to pass.\n",
      "    \n",
      "        You can load from a loc and pass subjects, the subjects\n",
      "        from each source will be merged.\n",
      "    \n",
      "        This parameter is compatible with groups / stratify.\n",
      "    \n",
      "        (default = None)\n",
      "    \n",
      "    show : bool, optional\n",
      "        By default, if True, information about the defined validation\n",
      "        strategy will be shown, including a dataframe if stratify is defined.\n",
      "    \n",
      "        (default = True)\n",
      "    \n",
      "    show_original : bool, optional\n",
      "        By default when you define stratifying behavior, a dataframe will\n",
      "        be displayed. This param controls if that dataframe shows original\n",
      "        names, or if False, then it shows the internally used names.\n",
      "    \n",
      "        (default = True)\n",
      "    \n",
      "    Notes\n",
      "    ----------\n",
      "    Validation strategy choices are explained in more detail:\n",
      "    \n",
      "    - Random\n",
      "        Just make validation splits randomly.\n",
      "    \n",
      "    - Group Preserving\n",
      "        Make splits that ensure subjects that are\n",
      "        part of specific group are all within the same fold\n",
      "        e.g., split by family, so that people with the same family id\n",
      "        are always a part of the same fold.\n",
      "    \n",
      "    - Stratifying\n",
      "        Make splits such that the distribution of a given\n",
      "        group is as equally split between two folds as possible,\n",
      "        so simmilar to matched halves or\n",
      "        e.g., in a binary or categorical predictive context,\n",
      "        splits could be done to ensure roughly equal distribution\n",
      "        of the dependent class.\n",
      "    \n",
      "    For now, it is possible to define only one overarching strategy\n",
      "    (One could imagine combining group preserving splits\n",
      "    while also trying to stratify for class,\n",
      "    but the logistics become more complicated).\n",
      "    Though, within one strategy it is certainly possible to\n",
      "    provide multiple values\n",
      "    e.g., for stratification you can stratify by target\n",
      "    (the dependent variable to be predicted)\n",
      "    as well as say sex, though with addition of unique value,\n",
      "    the size of the smallest unique group decreases.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ML.Define_Validation_Strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for group preserving behavior, as we are interested in keep families within the same folds, we supply an argument for groups. Specifically, we use the name of the column loaded within self.strat\n",
    "\n",
    "Notably as well is that defining a validation strategy is used to define global split behavior, which means the defined validation behavior will effect the train test split, as well as the internal splits used in modelling. We can re-define the original validation strategy at any point, even after defining a global train test split (why? e.g., in order to test within just the train set the effect of putting all the subjects with any nan as train only)\n",
    "\n",
    "The extra feature we will add to the split is defining all subjects with any missing measurements to be train only, this means these subjects will always be put in the training fold, in both the global split and for internal CV and even nested internal parameter search CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total valid overlapping subjects = 11519\n",
      "Removing non overlapping subjects from loaded data, covars, ect...\n",
      "\n",
      "Preparing final data, in self.all_data\n",
      "Any changes to loaded data, covars or strat will not be included, from now on.\n",
      "\n",
      "Final data (w/ target) for modeling loaded shape: (11519, 1059)\n",
      "2384 Train only subjects defined.\n",
      "Those subjects are excluded from the below stats!\n",
      "\n",
      "CV defined with group preserving over 8029 unique values.\n"
     ]
    }
   ],
   "source": [
    "ML.Define_Validation_Strategy(groups='rel_family_id', train_only_subjects='nan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note explictly, \"Preparing final data, in self.all_data\n",
    "Any changes to loaded data, covars or strat will not be included, from now on.\"\n",
    "\n",
    "If you want to load new data or a new target for example, you need to restart the notebook, as any changes made with loading functions will not effect the data to be used in modeling and testing ect..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly before we get to modelling, we want to define a global train-test split, so that we can perform model exploration, and parameter tuning ect... on a training set, and leave a left-out testing set to eventually test with out final selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing split on 8516 subjects with 3003 considered train only!\n",
      "random_state: 1\n",
      "Test split size: 0.35\n",
      "\n",
      "Performed train test split\n",
      "Train size: 8549\n",
      "Test size:  2970\n"
     ]
    }
   ],
   "source": [
    "ML.Train_Test_Split(test_size=.35) #Lets use .35, as train only subjects will not be considered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note above for the curious, 3003 subjects are considered train only, event though we only had 2384 with NaN. This is because we are defining group preserving behavior on family id, so not only do we need to keep those subjects in the training set, but keep all of their family members in the training set. We know now that no family id is in both the train and test set - but for the perhaps rightfully paranoid we can make sure of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique family ids in train:  7123\n",
      "Unique family ids in test:  2600\n",
      "Overlap :  0\n"
     ]
    }
   ],
   "source": [
    "train_ids = set(ML.strat['rel_family_id_Strat'].loc[ML.train_subjects])\n",
    "test_ids = set(ML.strat['rel_family_id_Strat'].loc[ML.test_subjects])\n",
    "\n",
    "print('Unique family ids in train: ', len(train_ids))\n",
    "print('Unique family ids in test: ', len(test_ids))\n",
    "print('Overlap : ', len(train_ids.intersection(test_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here might also be a good time to save a copy of the object we have created, if that is desired behavior. We are going to save it in our defined log_dr, and use the low_memory flag, which doesn't save explicitly loaded self.data, self.covars ect... and just stores the final self.all_data for modelling (which we have already implicitly created). Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_loc = os.path.join(ML.exp_log_dr, 'Sex.ML')\n",
    "ML.Save(save_loc, low_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now first thing to note is, since we set low_memory to false, we will can see that data, and targets ect.. are now deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 0), (0, 0))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML.data.shape, ML.targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And only all_data remains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11519, 1059)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML.all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can for example now delete our original ML object and then re-load the saved one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCD_ML object loaded from save!\n"
     ]
    }
   ],
   "source": [
    "del ML\n",
    "ML = Load(save_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make sure it worked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11519, 1059)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML.all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of modeling, is to define some default values. There are admittedly a lot, but most can be ignored, and tend to offer optional functionality. Lets look through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method Set_Default_ML_Params in module ABCD_ML.main._ML:\n",
      "\n",
      "Set_Default_ML_Params(problem_type='default', target='default', model='default', model_params='default', metric='default', weight_metric='default', imputer='default', imputer_scope='default', imputer_params='default', scaler='default', scaler_scope='default', scaler_params='default', transformer='default', transformer_scope='default', transformer_params='default', sampler='default', sample_on='default', sampler_params='default', feat_selector='default', feat_selector_params='default', ensemble='default', ensemble_split='default', ensemble_params='default', splits='default', n_repeats='default', search_type='default', search_splits='default', search_n_iter='default', feats_to_use='default', subjects_to_use='default', feat_importances='default', feat_importances_params='default', n_jobs='default', random_state='default', compute_train_score='default', cache='default', extra_params='default') method of ABCD_ML.main.ABCD_ML.ABCD_ML instance\n",
      "    Sets self.default_ML_params dictionary with user passed or default\n",
      "    values. In general, if any argument is left as 'default' and it has\n",
      "    not been previously defined, it will be set to a default value,\n",
      "    sometimes passed on other values. See notes for rationale behind\n",
      "    default ML params.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    problem_type : str, optional\n",
      "    \n",
      "        - 'regression'\n",
      "            For ML on float target data.\n",
      "    \n",
      "        - 'binary'\n",
      "            For ML on binary target data.\n",
      "    \n",
      "        - 'categorical'\n",
      "            For ML on categorical target data, as multiclass.\n",
      "    \n",
      "        - 'multilabel'\n",
      "            On categorical multilabel data.\n",
      "    \n",
      "        - 'default'\n",
      "            Use 'regression', if nothing else already defined.\n",
      "    \n",
      "        If 'default', and not already defined, set to 'regression'\n",
      "        (default = 'default')\n",
      "    \n",
      "    target : int or str, optional\n",
      "        The loaded target in which to use during modelling.\n",
      "        This can be the int index, or the name of the target column.\n",
      "        If only one target is loaded, just leave as default.\n",
      "    \n",
      "        If 'default', and not already defined, set to 0\n",
      "        (default = 'default')\n",
      "    \n",
      "    model : str or list of str\n",
      "        Each string refers to a type of model to train.\n",
      "        If a list of strings is passed then an ensemble model\n",
      "        will be created over all individual models.\n",
      "    \n",
      "        For a full list of supported options call:\n",
      "        :func:`Show_Models` or view the docs at :ref:`Models`\n",
      "    \n",
      "        If 'default', and not already defined, set to 'linear'\n",
      "        (default = 'default')\n",
      "    \n",
      "    model_params : int, str, or list of\n",
      "        Each `model` has atleast one default parameter distribution\n",
      "        saved with it.\n",
      "    \n",
      "        This parameter is used to select between different\n",
      "        distributions to be used with different search types,\n",
      "        when `search_type` == None, `model_params` is automatically\n",
      "        set to default 0.\n",
      "    \n",
      "        This parameter can be selected with either an integer index\n",
      "        (zero based), or the str name for a given `model`.\n",
      "        Likewise with `model`, if passed list input, this means\n",
      "        a list was passed to `model` and the indices should correspond.\n",
      "    \n",
      "        The different parameter distributions avaliable for each\n",
      "        `model`, can be shown by calling :func:`Show_Models`\n",
      "        or on the docs at :ref:`Models`\n",
      "    \n",
      "        If 'default', and not already defined, set to 0\n",
      "        (default = 'default')\n",
      "    \n",
      "    metric : str or list, optional\n",
      "        Indicator for which metric(s) to use for calculating\n",
      "        score and during model parameter selection.\n",
      "        If `metric` left as 'default', then the default metric\n",
      "        for that problem types will be used.\n",
      "        Note, some metrics are only avaliable for certain problem types.\n",
      "    \n",
      "        For a full list of supported metrics call:\n",
      "        :func:`Show_Metrics` or view the docs at :ref:`Metrics`\n",
      "    \n",
      "        If 'default', and not already defined, set to default\n",
      "        metric for the problem type.\n",
      "    \n",
      "        - 'regression'  : 'r2'\n",
      "        - 'binary'      : 'macro roc auc'\n",
      "        - 'categorical' : 'macro f1'\n",
      "        - 'multilabel' : 'macro roc auc'\n",
      "    \n",
      "        (default = 'default')\n",
      "    \n",
      "    weight_metric : bool, list of bool or 'default', optional\n",
      "        If True, then the metric of interest will be weighted within\n",
      "        each repeated fold by the number of subjects in that validation set.\n",
      "        This parameter only makes sense for custom split behavior where \n",
      "        validation folds end up with different sizes. When default CV schemes are\n",
      "        used there is no point weighting by very simmilar numbers.\n",
      "    \n",
      "        If you are passing mutiple metrics, then you can also pass a \n",
      "        list of values for weight_metric, with each value as True or False\n",
      "        as to if the corresponding metric by index should be weighted.\n",
      "    \n",
      "        As a reminder, the first metric specified will be used as the\n",
      "        parameter to optimize if a hyperparameter search is conducted.\n",
      "        Likewise, if it is specified that the first metric be weighted,\n",
      "        then the weighted metric will be used in the hyper-param search!\n",
      "    \n",
      "        If 'default', and not already defined, set to False\n",
      "        (default = 'default')\n",
      "    \n",
      "      imputer : str, list or None, optional\n",
      "        If there is any missing data (NaN's) that have been kept\n",
      "        within data or covars, then an imputation strategy must be\n",
      "        defined! This param controls the imputer to use, along with\n",
      "        `imputer_scope` to determine what each imputer should cover.\n",
      "        A single str can be passed, or a list of strs.\n",
      "    \n",
      "        There are a number of pre-defined imputers to select from,\n",
      "        but the user can also pass a valid model str indicator here.\n",
      "        This model str refers to the base_estimator to be used in\n",
      "        an IterativeImputer, see :class:`sklearn.impute.IterativeImputer`\n",
      "    \n",
      "        If a model str is passed, then it must be a valid model\n",
      "        for whatever scope is passed additional. If the `imputer_scope`\n",
      "        passed is 'float' or specific set of column names, then a regression\n",
      "        model type will be selected. If the scope is 'binary' or 'categorical',\n",
      "        then a binary / multiclass model type will be selected.\n",
      "        (Note: categorical cols are converted to multiclass first if nec.)\n",
      "    \n",
      "        For a full list of supported options call:\n",
      "        :func:`Show_Imputers` or view the docs at :ref:`Imputers`\n",
      "    \n",
      "        If 'default', and not already defined, set to ['mean', 'median']\n",
      "        (default = 'default')\n",
      "    \n",
      "    imputer_scope : str, list or None, optional\n",
      "        The `imputer_scope` param determines the scope,\n",
      "        or rather which columns the imputer should fill\n",
      "        (in data / covars), for each `imputer` passed.\n",
      "        Options are,\n",
      "    \n",
      "        - 'float'\n",
      "            To apply to all non-categorical columns, in both\n",
      "            loaded data and covars.\n",
      "    \n",
      "        - 'cat' or 'categorical'\n",
      "            To apply to just loaded categorical data.\n",
      "    \n",
      "        - array-like of strs\n",
      "            Can pass specific col names in as array-like\n",
      "            to select only those cols.\n",
      "    \n",
      "        If 'default', and not already defined, set to ['float', 'cat']\n",
      "        (default = 'default')\n",
      "    \n",
      "    imputer_params : int, str or list of\n",
      "        Each `imputer` has atleast one param distribution,\n",
      "        which can be selected with an int index, or a corresponding\n",
      "        str name. Likewise, a user can pass in a dictionary with their\n",
      "        own custom values.\n",
      "    \n",
      "        This parameter is used to select between different\n",
      "        distributions to be used with different search types,\n",
      "        when `search_type` == None, `model_params` is automatically\n",
      "        set to default 0.\n",
      "    \n",
      "        The different parameter distributions avaliable for each\n",
      "        `imputer`, can be shown by calling :func:`Show_Imputers`\n",
      "        or on the docs at :ref:`Imputers`\n",
      "    \n",
      "        Note: If a model was passed to the imputer, then\n",
      "        `imputer_params` will refer to the parameters for that\n",
      "        base model!\n",
      "    \n",
      "        If 'default', and not already defined, set to 0\n",
      "        (default = 'default')\n",
      "    \n",
      "    scaler : str, list or None, optional\n",
      "        `scaler` refers to the type of scaling to apply\n",
      "        to the saved data (just data, not covars) during model evaluation.\n",
      "        If a list is passed, then scalers will be applied in that order.\n",
      "        If None, then no scaling will be applied.\n",
      "    \n",
      "        For a full list of supported options call:\n",
      "        :func:`Show_Scalers` or view the docs at :ref:`Scalers`\n",
      "    \n",
      "        If 'default', and not already defined, set to 'standard'\n",
      "        (default = 'default')\n",
      "    \n",
      "    scaler_scope : str, list or None, optional\n",
      "        `scaler_scope` refers to the \"scope\" or rather columns in\n",
      "        which each passed scaler (if multiple), should be applied.\n",
      "        If a list of scalers is passed, then scopes should also be a\n",
      "        list with index corresponding to each scaler.\n",
      "        If less then the number of scalers are passed, then the\n",
      "        first passed scaler scope will be used for all of the\n",
      "        remaining scalers. Likewise, if no scaler is passed, this\n",
      "        parameter will be ignored!\n",
      "    \n",
      "        Each scaler scope can be either,\n",
      "    \n",
      "        - 'float'\n",
      "            To apply to all non-categorical columns, in both\n",
      "            loaded data and covars.\n",
      "    \n",
      "        - 'data'\n",
      "            To apply to all loaded data columns only.\n",
      "    \n",
      "        - 'float covars' or 'fc'\n",
      "            To apply to all non-categorical, float covars columns only.\n",
      "    \n",
      "        - 'all'\n",
      "            To apply to everything, regardless of float/cat or data/covar.\n",
      "    \n",
      "        - 'cat' or 'categorical'\n",
      "            To apply to just loaded categorical data.\n",
      "    \n",
      "        - 'covars'\n",
      "            To apply to all loaded covar columns only.\n",
      "    \n",
      "        - array-like of strs\n",
      "            Can pass specific col names in as array-like\n",
      "            to select only those cols.\n",
      "    \n",
      "        If 'default', and not already defined, set to 'float'\n",
      "        (default = 'default')\n",
      "    \n",
      "    scaler_params : int, str, or list of, optional\n",
      "        Each `scaler` has atleast one default parameter distribution\n",
      "        saved with it.\n",
      "    \n",
      "        This parameter is used to select between different\n",
      "        distributions to be used with different search types,\n",
      "        when `search_type` == None, `model_params` is automatically\n",
      "        set to default 0.\n",
      "    \n",
      "        This parameter can be selected with either an integer index\n",
      "        (zero based), or the str name for a given `scaler`.\n",
      "        Likewise with `scaler`, if passed list input, this means\n",
      "        a list was passed to `scaler` and the indices should correspond.\n",
      "    \n",
      "        The different parameter distributions avaliable for each\n",
      "        `scaler`, can be shown by calling :func:`Show_Scalers`\n",
      "        or on the docs at :ref:`Scalers`\n",
      "    \n",
      "        If 'default', and not already defined, set to 0\n",
      "        (default = 'default')\n",
      "    \n",
      "    transformer : str, list or None, optional\n",
      "        Transformers are any type of transformation to\n",
      "        the data that changes the number of features in non-deterministic\n",
      "        or not simply removal (i.e., as in feat_selectors), for example\n",
      "        applying a PCA, where both the number of features change, but\n",
      "        also the new features do not 1:1 correspond to the original\n",
      "        features. \n",
      "    \n",
      "        For a full list of supported options call:\n",
      "        :func:`Show_Transformers` or view the docs at :ref:`Transformers`\n",
      "    \n",
      "    transformer_scope : str, list or None, optional\n",
      "        `transformer_scope` refers to the \"scope\" or rather columns in\n",
      "        which each passed scaler (if multiple), should be applied.\n",
      "        If a list of transformers is passed, then scopes should also be a\n",
      "        list with index corresponding to each transformer.\n",
      "        If less then the number of transformers are passed, then the\n",
      "        first passed transformer_scope will be used for all of the\n",
      "        remaining transformers. Likewise, if no transformer is passed, this\n",
      "        parameter will be ignored!\n",
      "    \n",
      "        Each transformer scope can be either,\n",
      "    \n",
      "        - 'float'\n",
      "            To apply to all non-categorical columns, in both\n",
      "            loaded data and covars.\n",
      "    \n",
      "        - 'data'\n",
      "            To apply to all loaded data columns only.\n",
      "    \n",
      "        - 'float covars' or 'fc'\n",
      "            To apply to all non-categorical, float covars columns only.\n",
      "    \n",
      "        - 'all'\n",
      "            To apply to everything, regardless of float/cat or data/covar.\n",
      "    \n",
      "        - 'cat' or 'categorical'\n",
      "            To apply to just loaded categorical data.\n",
      "    \n",
      "        - 'covars'\n",
      "            To apply to all loaded covar columns only.\n",
      "    \n",
      "        - array-like of strs\n",
      "            Can pass specific col names in as array-like\n",
      "            to select only those cols.\n",
      "    \n",
      "        If 'default', and not already defined, set to 'float'\n",
      "        (default = 'default')\n",
      "    \n",
      "    transformer_params : int, str, or list of, optional\n",
      "        Each `transformer` has atleast one default parameter distribution\n",
      "        saved with it.\n",
      "    \n",
      "        This parameter is used to select between different\n",
      "        distributions to be used with different search types,\n",
      "        when `search_type` == None, `model_params` is automatically\n",
      "        set to default 0.\n",
      "    \n",
      "        This parameter can be selected with either an integer index\n",
      "        (zero based), or the str name for a given `transformer`.\n",
      "        Likewise with `transformer`, if passed list input, this means\n",
      "        a list was passed to `transformer` and the indices should correspond.\n",
      "    \n",
      "        The different parameter distributions avaliable for each\n",
      "        `transformer`, can be shown by calling :func:`Show_Transformers`\n",
      "        or on the docs at :ref:`Transformers`\n",
      "    \n",
      "        If 'default', and not already defined, set to 0\n",
      "        (default = 'default')\n",
      "    \n",
      "    sampler : str, list or None, optional\n",
      "        `sampler` refers optional to the type of resampling\n",
      "        to apply within the model pipeline - to correct for\n",
      "        imbalanced class distributions. These are different\n",
      "        techniques for over sampling under distributed classed\n",
      "        and under sampling over distributed ones.\n",
      "        If a list is passed, then samplers will be fit and applied\n",
      "        in that order.\n",
      "    \n",
      "        For a full list of supported options call:\n",
      "        :func:`Show_Samplers` or view the docs at :ref:`Samplers`\n",
      "    \n",
      "        If 'default', and not already defined, set to None\n",
      "        (default = 'default')\n",
      "    \n",
      "    sample_on : str, list or None, optional\n",
      "        If `sampler` is set, then for each sampler used,\n",
      "        this `sample_on` parameter must be set. This parameter\n",
      "        dictates what the sampler should use as its class to\n",
      "        re-sample. For example, the most typical case is passing\n",
      "        in 't' which will then resample according to the\n",
      "        distribution of the target variable.\n",
      "        (If multipled loaded, then whichever is is selected in target param),\n",
      "        The user can also pass in\n",
      "        the names of any loaded strat columns (See: :func:`Load_Strat`),\n",
      "        or a combination as list of both,\n",
      "        similar to input accepted by the `stratify` param\n",
      "        in :func:`Define_Validation_Strategy`.\n",
      "    \n",
      "        Note: The way sample_on is coded, any passed col name which is not\n",
      "        loaded in Strat, will be interpreted as sample the target variable!\n",
      "        That is why the default value is just t, but you can pass anything that\n",
      "        isnt a loaded strat col, to have it sample on strat.\n",
      "    \n",
      "        When a list is passed to one sampler, then the unique combination\n",
      "        of values fis created, and sampled on.\n",
      "    \n",
      "        In the case where a list of a samplers is passed, then a\n",
      "        list of `sample_on` params should be passed, where the index\n",
      "        correspond. `sample_on` would look like a list of lists in the case\n",
      "        where you want to pass a combination of options, or differing combos\n",
      "        to different samplers.\n",
      "    \n",
      "        If 'default', and not already defined, set to 'targets'\n",
      "        (default = 'default')\n",
      "    \n",
      "    sampler_params :  int, str, or list of\n",
      "        Each `sampler` has atleast one default parameter distribution\n",
      "        saved with it.\n",
      "    \n",
      "        This parameter is used to select between different\n",
      "        distributions to be used with different search types,\n",
      "        when `search_type` == None, `model_params` is automatically\n",
      "        set to default 0.\n",
      "    \n",
      "        This parameter can be selected with either an integer index\n",
      "        (zero based), or the str name for a given `sampler`.\n",
      "        Likewise with `sampler`, if passed list input, this means\n",
      "        a list was passed to `sampler` and the indices should correspond.\n",
      "    \n",
      "        The different parameter distributions avaliable for each\n",
      "        `sampler`, can be shown by calling :func:`Show_Samplers`\n",
      "        or on the docs at :ref:`Samplers`\n",
      "    \n",
      "        If 'default', and not already defined, set to 0\n",
      "        (default = 'default')\n",
      "    \n",
      "    feat_selector : str, list or None, optional\n",
      "        `feat_selector` should be a str indicator or list of,\n",
      "        for which feature selection to use, if a list, they will\n",
      "        be applied in order.\n",
      "        If None, then no feature selection will be used.\n",
      "    \n",
      "        For a full list of supported options call:\n",
      "        :func:`Show_Feat_Selectors` or view the docs at :ref:`Feat Selectors`\n",
      "    \n",
      "        If 'default', and not already defined, set to None\n",
      "        (default = 'default')\n",
      "    \n",
      "    feat_selector_params : int, str, or list of\n",
      "         Each `feat_selector` has atleast one default parameter distribution\n",
      "        saved with it.\n",
      "    \n",
      "        This parameter is used to select between different\n",
      "        distributions to be used with different search types,\n",
      "        when `search_type` == None, `model_params` is automatically\n",
      "        set to default 0.\n",
      "    \n",
      "        This parameter can be selected with either an integer index\n",
      "        (zero based), or the str name for a given `feat_selector` param option.\n",
      "        Likewise with `feat_selector`, if passed list input, this means\n",
      "        a list was passed to `feat_selector` and the indices should correspond.\n",
      "    \n",
      "        The different parameter distributions avaliable for each\n",
      "        `feat_selector`, can be shown by calling :func:`Show_Feat_Selectors`\n",
      "        or on the docs at :ref:`Feat Selectors`\n",
      "    \n",
      "        If 'default', and not already defined, set to 0\n",
      "        (default = 'default')\n",
      "    \n",
      "    ensemble :  str or list of str,\n",
      "        Each string refers to a type of ensemble to train,\n",
      "        or 'basic ensemble' (default) for base behavior.\n",
      "        Base ensemble behavior is either to not ensemble,\n",
      "        if only one model type is passed,\n",
      "        or when multiple models are passed,\n",
      "        to simply train each one independently and\n",
      "        average the predictions at test time (or max vote).\n",
      "    \n",
      "        The user can optionally pass other ensemble types,\n",
      "        though with other types of ensembles there are two\n",
      "        different types to consider. One additional set of\n",
      "        ensemble types will require a parameter to be set for\n",
      "        `ensemble_split`, as these ensembles need to be fit\n",
      "        on a left out portion of the data. This ensemble split\n",
      "        will importantly always do a stratified split for now,\n",
      "        and not uphold any defined CV behavior.\n",
      "    \n",
      "        The other possible ensemble type is one based on a single\n",
      "        estimator, for example Bagging. In this case, if a list of models\n",
      "        is passed, a Basic Ensemble will be fit over the models, and\n",
      "        the Bagging Classifier or Regressor built on that ensemble of\n",
      "        models.\n",
      "    \n",
      "        If a list is passed to ensemble, then every\n",
      "        item in the list must be a valid str indicator for\n",
      "        a non 'basic ensemble' ensemble type, and each ensemble\n",
      "        object passed will be fitted independly and then averaged\n",
      "        using the 'basic ensemble' behvaior... so an ensemble of ensembles.\n",
      "    \n",
      "        For a full list of supported options call:\n",
      "        :func:`Show_Ensembles` or view the docs at :ref:`Ensemble Types`\n",
      "    \n",
      "        If 'default', and not already defined, set to 'basic ensemble'\n",
      "        (default = 'default')\n",
      "    \n",
      "    ensemble_split : float, int or None, optional\n",
      "        If an ensemble(s) that requires fitting is passed,\n",
      "        i.e., not \"basic ensemble\", then this param is\n",
      "        the porportion of the train_data within each fold to\n",
      "        use towards fitting the ensemble objects.\n",
      "        If multiple ensembles are passed, they are all\n",
      "        fit with the same fold of data.\n",
      "    \n",
      "        If 'default', and not already defined, set to .2\n",
      "        (default = 'default')\n",
      "    \n",
      "    ensemble_params : int, str, or list of, optional\n",
      "         Each `ensemble` has atleast one default parameter distribution\n",
      "        saved with it.\n",
      "    \n",
      "        This parameter is used to select between different\n",
      "        distributions to be used with different search types,\n",
      "        when `search_type` == None, `model_params` is automatically\n",
      "        set to default 0.\n",
      "    \n",
      "        This parameter can be selected with either an integer index\n",
      "        (zero based), or the str name for a given `ensemble` param option.\n",
      "        Likewise with `ensemble`, if passed list input, this means\n",
      "        a list was passed to `ensemble` and the indices should correspond.\n",
      "    \n",
      "        If 'default', and not already defined, set to 0\n",
      "        (default = 'default')\n",
      "    \n",
      "    splits : int, str or list, optional\n",
      "        If `splits` is an int, then :func:`Evaluate` performs a repeated\n",
      "        k-fold model evaluation, where `splits` refers to the k, and\n",
      "        `n_repeats` refers to the number of repeats.\n",
      "        E.g., if set to 3, then a 3-fold CV will be performed at each repeat.\n",
      "    \n",
      "        Note: the splits will be determined according to the validation\n",
      "        strategy defined in :func:`Define_Validation_Strategy` if any!\n",
      "    \n",
      "        Alternatively, `splits` can be set to a str or list of\n",
      "        strings, where each str refers to a column name loaded\n",
      "        within strat! In this case, a leave-one-out CV will be\n",
      "        performed on that strat value, or combination of values.\n",
      "        The number of folds will therefore be equal to the number of unique\n",
      "        values, and can optionally be repeated with `n_repeats` set to > 1.\n",
      "    \n",
      "        If 'default', and not already defined, set to 3\n",
      "        (default = 'default')\n",
      "    \n",
      "    n_repeats : int or 'default', optional\n",
      "        :func:`Evaluate` performs a repeated k-fold model evaluation,\n",
      "        or a left out CV, based on input. `n_repeats` refers to the number of\n",
      "        times to repeat this.\n",
      "    \n",
      "        Note: In the case where `splits` is set to a strat col and therefore\n",
      "        a leave-one-out CV, setting `n_repeats` > 1, with a fixed random seed\n",
      "        will be redundant.\n",
      "    \n",
      "        If 'default', and not already defined, set to 2\n",
      "        (default = 'default')\n",
      "    \n",
      "    search_type : {None, str}\n",
      "        The type of parameter search to conduct if any. If set to None,\n",
      "        no hyperparameter search will be conducted.\n",
      "    \n",
      "        The option is to pass the name of a nevergrad optimizer.\n",
      "    \n",
      "        If 'default', and not already defined, set to None\n",
      "        (default = 'default')\n",
      "    \n",
      "    search_splits : int, str or list, optional\n",
      "        The number of internal folds to use during\n",
      "        model k-fold parameter selection if `search_splits` is an int.\n",
      "    \n",
      "        Note: the splits will be determined according to the validation\n",
      "        strategy defined in :func:`Define_Validation_Strategy` if any!\n",
      "    \n",
      "        Alternatively, `search_splits` can be set to a str or list of\n",
      "        strings, where each str refers to a column name loaded\n",
      "        within strat! In this case, a leave-one-out CV will be\n",
      "        performed on that strat value, or combination of values.\n",
      "        The number of search CV folds will therefore be equal to the\n",
      "        number of unique values.\n",
      "    \n",
      "        If 'default', and not already defined, set to 3\n",
      "        (default = 'default')\n",
      "    \n",
      "    search_n_iter : int or 'default', optional\n",
      "        The number of random search parameters to try, used\n",
      "        only if using random search.\n",
      "    \n",
      "        if 'default', and not already defined, set to 10.\n",
      "        (default = 'default')\n",
      "    \n",
      "    feats_to_use : {'all', 'data', 'covars'} or array, optional\n",
      "        This parameter allows the user to optionally\n",
      "        run an expiriment with a subset of the loaded features\n",
      "        / columns. Typically either only the loaded\n",
      "        data and/or only the loaded covars. Specific key words\n",
      "        exist for selecting these, or alternatively, an array-like\n",
      "        of column keys can be passed in explicitly.\n",
      "    \n",
      "        - 'all'\n",
      "            Uses all data + covars loaded\n",
      "    \n",
      "        - 'data'\n",
      "            Uses only the loaded data, and drops covars if any.\n",
      "    \n",
      "        - 'covars'\n",
      "            Uses only the loaded covars, and drops data if any\n",
      "    \n",
      "        - array-like of strs\n",
      "            Can pass specific col names in as array-like\n",
      "            to select only those cols.\n",
      "    \n",
      "        - wild card str or array-like\n",
      "            If user passed str doesn't match with\n",
      "            valid col name, will use as wildcard.\n",
      "    \n",
      "        The way the wild card system works is that if for all user\n",
      "        passed strs that do not match a column name, they will be treated\n",
      "        as wildcards. For example, if '._desikan' and '._lh' were passed\n",
      "        as wildcards, any column name with both '._desikan' and '._lh', will\n",
      "        be added to feats to use.\n",
      "    \n",
      "        You can also pass a list combination of any of the above,\n",
      "        for example you could pass ['covars', specific_column_name, wildcard]\n",
      "        to select all of the covariate columns, the specific column name(s)\n",
      "        and any extra columns which match the wildcard(s).\n",
      "    \n",
      "        if 'default', and not already defined, set to 'all'.\n",
      "        (default = 'default')\n",
      "    \n",
      "    subjects_to_use : 'all', array-like or str, optional\n",
      "        This parameter allows the user to optionally run\n",
      "        an Evaluation run with just a subset of the loaded subjects.\n",
      "        It is designed to be to be used after a global train test split\n",
      "        has been defined (see :func:`Train_Test_Split`), for cases such\n",
      "        as, creating and testing models on just Males, or just Females.\n",
      "    \n",
      "        If set to 'all' (as is by default), all avaliable subjects will be\n",
      "        used.\n",
      "    \n",
      "        `subjects_to_use` can accept either a specific array of subjects,\n",
      "        or even a loc of a text file (formatted one subject per line) in\n",
      "        which to read from. Note: do not pass a tuple of subjects, as that\n",
      "        is reserved for specifying special behavior.\n",
      "    \n",
      "        Alternatively, `subjects_to_use` will accept a tuple, (Note:\n",
      "        it must be a tuple!), where the first element is a loaded strat key,\n",
      "        or a list of, and the second is an int value. In this case,\n",
      "        `subjects_to_use`, will be set to the subset of subjects associated\n",
      "        with the specified strat values (or combination) that have that value.\n",
      "    \n",
      "        For example, if sex was loaded within strat, and ('sex', 0) was\n",
      "        passed to `subjects_to_use`, then :func:`Evaluate` would be run\n",
      "        on just those subjects with sex == 0.\n",
      "    \n",
      "        if 'default', and not already defined, set to 'all'.\n",
      "        (default = 'default')\n",
      "    \n",
      "    feat_importances : None, str or list, optional\n",
      "        This parameter controls which feature importances should\n",
      "        be calculated, and can be set to None, a single feature\n",
      "        importance, or a list of different types.\n",
      "    \n",
      "        Different feature importances are restricted by problem_type\n",
      "        in some cases, as well as will vary based on specific type of\n",
      "        model used. For example, only linear models and tree based models\n",
      "        are supported for calculating 'base' feature importances. With\n",
      "        'shap' feature importance, any underlying model is supported, but\n",
      "        only tree based and linear models can be computed quickly, with\n",
      "        other models requiring a great deal of computation.\n",
      "    \n",
      "        Please view :ref:`Feat Importances` to learn more about the different\n",
      "        options for calculating feature importance, as well as the\n",
      "        distinction between 'local' and 'global' measures of\n",
      "        feature importance, and also the tradeoffs and differences\n",
      "        between computing\n",
      "        feature importance based of only train data, only test or all\n",
      "        of the data.\n",
      "    \n",
      "        If 'default', and not already defined, set to 'base'\n",
      "        (default = 'default')\n",
      "    \n",
      "    feat_importances_params : int, str, dict or list of, optional\n",
      "        Different feature importances may vary on different\n",
      "        hyperparameters. If the selected feature importance has\n",
      "        hyperparameters, this parameter either selects from default\n",
      "        choices (using either int input, or str for selecting the name\n",
      "        of the preset). If a list of feat_importances is passed, a\n",
      "        corresponding list of feat_importances_params should be passed.\n",
      "    \n",
      "        A user-defined dictionary can passed as well, containing user\n",
      "        specified values. When only changing one\n",
      "        or two parameters from the default, any non-specified params\n",
      "        will be replaced with the default value.\n",
      "    \n",
      "        See the docs for which parameters are required by which\n",
      "        feature importance types, and for what the default values are.\n",
      "    \n",
      "        If 'default', and not already defined, set to 0\n",
      "        (default = 'default')\n",
      "    \n",
      "    n_jobs : int or 'default', optional\n",
      "        The number of jobs to use (if avaliable) during training ML models.\n",
      "        This should be the number of procesors avaliable for fastest run times.\n",
      "    \n",
      "        if 'default', and not already defined, set to 1.\n",
      "        (default = 'default')\n",
      "    \n",
      "    random_state : int, RandomState instance, None or 'default', optional\n",
      "        Random state, either as int for a specific seed, or if None then\n",
      "        the random seed is set by np.random.\n",
      "    \n",
      "        If 'default', use the saved value within self\n",
      "        ( Defined in :func:`__init__` )\n",
      "        Or the user can define a different random state for use in ML.\n",
      "        (default = 'default')\n",
      "    \n",
      "    compute_train_score : bool, optional\n",
      "        If set to True, then :func:`Evaluate` and :func:`Test`\n",
      "        will compute, and print, training scores along with\n",
      "        validation / test scores.\n",
      "    \n",
      "        if 'default', and not already defined, set to False.\n",
      "        (default = 'default')\n",
      "    \n",
      "    cache : None or str, optional\n",
      "        sklearn pipeline's allow the caching of fitted transformers.\n",
      "        If this behavior is desired (in the cases where a non-model step take\n",
      "        a long time to fit), then a str indicating the directory where\n",
      "        the cache should be stored should be passed.\n",
      "    \n",
      "        Note: cache dr's are not automatically removed, as different Evaluate\n",
      "        calls may benefit from overlapping cached steps. That said, throughout\n",
      "        a longer expiriment, the size of the cache will grow fairly quickly!\n",
      "        Therefore be careful to delete the cache when you are done, and to\n",
      "        only use this option if you have the free storage.\n",
      "    \n",
      "    extra_params : dict or 'default', optional\n",
      "        Any extra params being passed. Typically, extra params are\n",
      "        added when the user wants to provide a specific model/classifier,\n",
      "        or data scaler, with updated (or new) parameters.\n",
      "        These can be supplied by creating another dict within extra_params.\n",
      "        E.g., ::\n",
      "    \n",
      "            extra_params[model_name] = {'model_param' : new_value}\n",
      "    \n",
      "        Where model param is a valid argument for that model, and model_name in\n",
      "        this case is the str indicator passed to model.\n",
      "        If 'default', and not already defined, set to empty dict.\n",
      "    \n",
      "        (default = 'default')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ML.Set_Default_ML_Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default ML params set within self.default_ML_params.\n",
      "----------------------\n",
      "problem_type: binary\n",
      "target: 0\n",
      "model: linear\n",
      "metric: ['matthews', 'roc auc']\n",
      "imputer: ['mean', 'median']\n",
      "imputer_scope: ['float', 'cat']\n",
      "scaler: robust\n",
      "scaler_scope: float\n",
      "transformer: None\n",
      "transformer_scope: float\n",
      "sampler: None\n",
      "sample_on: targets\n",
      "feat_selector: None\n",
      "splits: 3\n",
      "n_repeats: 2\n",
      "weight_metric: False\n",
      "search_splits: 3\n",
      "ensemble: basic ensemble\n",
      "ensemble_split: 0.2\n",
      "search_type: None\n",
      "model_params: 0\n",
      "imputer_params: 0\n",
      "scaler_params: 0\n",
      "transformer_params: 0\n",
      "sampler_params: 0\n",
      "feat_selector_params: 0\n",
      "ensemble_params: 0\n",
      "n_jobs: 8\n",
      "search_n_iter: 30\n",
      "feats_to_use: all\n",
      "subjects_to_use: all\n",
      "compute_train_score: False\n",
      "random_state: 1\n",
      "feat_importances: base\n",
      "feat_importances_params: 0\n",
      "cache: None\n",
      "extra_params: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Only will set ones that change below, all other ones are left as default.\n",
    "ML.Set_Default_ML_Params(problem_type = 'binary', # Easy choice...\n",
    "                         metric = ['matthews', 'roc auc'], # Good thresholded and non-thresholded binary metrics\n",
    "                         scaler = 'robust',\n",
    "                         search_n_iter = 30,\n",
    "                         n_jobs = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define different levels of verbose output, w/ options like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method Set_Default_ML_Verbosity in module ABCD_ML.main._ML:\n",
      "\n",
      "Set_Default_ML_Verbosity(save_results='default', progress_bar='default', show_init_params='default', fold_name='default', time_per_fold='default', score_per_fold='default', fold_sizes='default', best_params='default', save_to_logs='default') method of ABCD_ML.main.ABCD_ML.ABCD_ML instance\n",
      "    This function allows setting various verbosity options that effect\n",
      "    output during :func:`Evaluate` and :func:`Test`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    save_results : bool, optional\n",
      "        If True, all results returned by Evaluate\n",
      "        will be saved within the log dr (if one exists!),\n",
      "        under run_name + .eval, and simmilarly for results\n",
      "        returned by Test, but as run_name + .test.\n",
      "    \n",
      "        if 'default', and not already defined, set to False.\n",
      "        (default = 'default')\n",
      "    \n",
      "    progress_bar : bool, optional\n",
      "        If True, a progress bar, implemented in the python\n",
      "        library tqdm, is used to show progress during use of\n",
      "        :func:`Evaluate` , If False, then no progress bar is shown.\n",
      "        This bar should work both in a notebook env and outside one,\n",
      "        assuming self.notebook has been set correctly.\n",
      "    \n",
      "        if 'default', and not already defined, set to True.\n",
      "        (default = 'default')\n",
      "    \n",
      "    show_init_params : bool, optional\n",
      "        If True, then print/show the parameters used before running\n",
      "        Evaluate / Test. If False, then don't print the params used.\n",
      "    \n",
      "        if 'default', and not already defined, set to True.\n",
      "        (default = 'default')\n",
      "    \n",
      "    fold_name : bool, optional\n",
      "        If True, prints a rough measure of progress via\n",
      "        printing out the current fold (somewhat redundant with the\n",
      "        progress bar if used, except if used with other params, e.g.\n",
      "        time per fold, then it is helpful to have the time printed\n",
      "        with each fold). If False, nothing is shown.\n",
      "    \n",
      "        if 'default', and not already defined, set to False.\n",
      "        (default = 'default')\n",
      "    \n",
      "    time_per_fold : bool, optional\n",
      "        If True, prints the full time that a fold took to complete.\n",
      "    \n",
      "        if 'default', and not already defined, set to False.\n",
      "        (default = 'default')\n",
      "    \n",
      "    score_per_fold : bool, optional\n",
      "        If True, displays the score for each fold, though slightly less\n",
      "        formatted then in the final display.\n",
      "    \n",
      "        if 'default', and not already defined, set to False.\n",
      "        (default = 'default')\n",
      "    \n",
      "    fold_sizes : bool, optional\n",
      "        If True, will show the number of subjects within each train\n",
      "        and val/test fold.\n",
      "    \n",
      "        if 'default', and not already defined, set to False.\n",
      "        (default = 'default')\n",
      "    \n",
      "    best_params : bool, optional\n",
      "        If True, print the best search params found after every\n",
      "        param search.\n",
      "    \n",
      "    save_to_logs : bool, optional\n",
      "        If True, then when possible, and with the selected model\n",
      "        verbosity options, verbosity ouput will be saved to the\n",
      "        log file.\n",
      "    \n",
      "        if 'default', and not already defined, set to False.\n",
      "        (default = 'default')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ML.Set_Default_ML_Verbosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default ML verbosity set within self.default_ML_verbosity.\n",
      "----------------------\n",
      "save_results: False\n",
      "progress_bar: True\n",
      "show_init_params: True\n",
      "fold_name: False\n",
      "time_per_fold: False\n",
      "score_per_fold: False\n",
      "fold_sizes: False\n",
      "best_params: False\n",
      "save_to_logs: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.Set_Default_ML_Verbosity()  # Default are fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed to modeling.\n",
    "\n",
    "\n",
    "The main function we use here is Evaluate. We won't bother looking at the help str as it has all of the same params as we just saw above, allowing you to proceed to with differing specific choices in addition to all set default values. Evaluate does have one unique param though, and that is run_name, which is the name in which the results of each run will be stored under in ML.eval_scores.\n",
    "\n",
    "We check what different model types we have avaliable also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit the sklearn documentation for more info on most of the dif. models\n",
      "Note: Param distributions with a Rand Distribution\n",
      "cannot be used in search_type = \"grid\"\n",
      "More information through this function is avaliable\n",
      "By passing optional extra optional params! Please view the help function for more info!\n",
      "Note: the str indicator actually passed during Evaluate / Test\n",
      "is listed as (\"str indicator\")\n",
      "\n",
      "Avaliable for Problem Type: binary\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "DecisionTreeClassifier (\"dt classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "LogisticRegression (\"elastic net logistic\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "GaussianNB (\"gaussian nb\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "GaussianProcessClassifier (\"gp classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "KNeighborsClassifier (\"knn classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "LogisticRegression (\"lasso logistic\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "LGBMClassifier (\"light gbm classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "LinearSVC (\"linear svm classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "LogisticRegression (\"logistic\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "MLPClassifier (\"mlp classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "RandomForestClassifier (\"random forest classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "LogisticRegression (\"ridge logistic\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "SGDClassifier (\"sgd classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "SVC (\"svm classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "XGBClassifier (\"xgb classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.Show_Models(problem_type='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at different metrics and scalers ect... with the \"Show\" style functions, but I generally prefer the interface on the documentation. E.g., https://abcd-ml.readthedocs.io/en/latest/options.html#id20 \n",
    "\n",
    "The Show interface might be a bit buggy as result, in general I really reccomend using the documentation to search through different options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some default ML params set, all we need to do to run an evaluation is simply: (with a just a single decision tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ML.Evaluate(model='dt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, its clear that running the full evaluation even with a very quick simple model like the decision tree if very intensive, all we have 1000+ features and thousands of subjects. One optional trick we can use, especially for this example, is to run expiriments with only a subset of the features, let's consider what we have loaded:\n",
    "\n",
    "- 'smri_thick_cort'\n",
    "- 'smri_sulc_cort'\n",
    "- 'smri_area_cort'\n",
    "- 'smri_vol_cort'\n",
    "- 'smri_t1w.white02_cort'\n",
    "- 'smri_t1w.gray02_cort'\n",
    "- 'smri_t1w.contrast_cort'\n",
    "\n",
    "Alright, so let's say we are only interested in cortical thickness, because why not. To limit our Evaluate call to using just cortical thickness features, all we have to do is provide that substring from above, 'smri_thick_cort', to the feats_to_use parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And like magic we reduce the overall runtime more then 10x, but also take a big hit to performance. Regardless, the decision tree model was never likely to give us our best answer, so we can continue on to trying different options, but first, lets set our feats to use as a default parameter so we don't have to type it in everytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to re-define our other defaults, the default params are state based\n",
    "ML.Set_Default_ML_Params(feats_to_use = 'smri_thick_cort') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try an elastic net model now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ML.Evaluate(model='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A just linear model appears to do much better then the decision tree. Before we try other models, let's take a look at the beta weights from the linear model (averaged over the 6 models, 2 repeated, 3 folds). A short hand for this is by just calling plot global feat importances directly, which will plot the feature importances for the last evaluate call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Plot_Global_Feat_Importances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can pass in the feature importances object itself, which can be found in results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we passed multiple feature importances to calculate they would appear in a list, \n",
    "print(len(results['FIs']))\n",
    "\n",
    "# If we show this object we see\n",
    "results['FIs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can either look at the importances in a dataframe, or pass the feature importance object to the plotting func\n",
    "results['FIs'][0].global_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Plot_Global_Feat_Importances(results['FIs'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, so the biggest features driving the model to predict female (0) vs. male (1) are mean thickness of the different hemispheres. Let's explore some different models before sticking with this straight linear one. One of my favorites to try is light gradient boosting machine, or light gbm (or lgbm). \n",
    "\n",
    "Note: lightgbm is not included in ABCD_ML's pip requiriments by default as on mac's especially there are some extra download steps. If you have not already, and would like to use the lightgbm package, please install the lightgbm packagae on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ML.Evaluate(model='light gbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until this point we have not been exploring any nested hyper-parameters, which for a linear and decision tree model is not a big deal, but fine tuning the lightgbm is fairly essential in order to get good performance. To tune parameters facebooks nevergrad package is used a backend optimizer which allows for a lot of interesting search types (https://abcd-ml.readthedocs.io/en/latest/search_types.html), but introduces a little bit of a learning curve for those interested in entering in custom hyperparameter distributions to search over.\n",
    "\n",
    "By default though, most classifiers have atleast one pre-set hyperparameter distributions to search over. We can see lightgbm's at https://abcd-ml.readthedocs.io/en/latest/options.html#light-gbm-classifier. Our choice here of what search type to use will be passed to the search_type param, and we will just start with a RandomSearch.\n",
    "\n",
    "When selecting a preset distribution to use we can either pass the index of the distribution to model_params, as e.g., 1, or we can pass the name of the distribution, in this case 'lgbm classifier dist1'. \n",
    "\n",
    "A few other parameters are useful now that we are moving to a hyperparameter search model, these are: the number of hyperparameters to try in each fold, search_n_iter- and the number of folds to use (or more special folds) to use in evaluating each set of hyperparameters, search_splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ML.Evaluate(model = 'light gbm',\n",
    "                      model_params = 1,\n",
    "                      search_type = 'RandomSearch',\n",
    "                      search_splits = 3,\n",
    "                      search_n_iter = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless of a search over params, our linear model still performs best. Let's try a few other models below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ML.Evaluate(model='elastic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ML.Evaluate(model = 'elastic',\n",
    "                      model_params = 1,\n",
    "                      search_type = 'RandomSearch',\n",
    "                      search_splits = 3,\n",
    "                      search_n_iter = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ML.Evaluate(model = 'svm',\n",
    "                      model_params = 1,\n",
    "                      search_type = 'RandomSearch',\n",
    "                      search_splits = 3,\n",
    "                      search_n_iter = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try with multiple data scalers now, just to show off that functionality, and still just the logistic regression. In this case it will first apply a robust scaler then the minmax scaler to the data in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ML.Evaluate(model='logistic', \n",
    "                      scaler = ['robust', 'minmax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
