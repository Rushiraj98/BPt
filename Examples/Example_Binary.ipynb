{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook goes through a simple binary classification example, explaining library functionality along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ABCD_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define directory with the 2.0_NDA_Data\n",
    "nda_dr = '/mnt/sdb2/2.0_ABCD_Data_Explorer/2.0_NDA_Data/'\n",
    "\n",
    "#This file stores the name mapping\n",
    "test_mapping_loc = nda_dr + 'ABCD_Release_ Notes_Data_Release_ 2.0/22. ABCD_Release_2.0_mapping_r.csv'\n",
    "\n",
    "#We will use as the neuroimaging data just the sMRI data\n",
    "test_data_loc1 = nda_dr + 'MRI/ABCD sMRI Part 1.csv'\n",
    "test_data_loc2 = nda_dr + 'MRI/ABCD sMRI Part 2.csv'\n",
    "\n",
    "#We will load target data (and covariate data) from here\n",
    "test_target_loc = nda_dr + 'Mental Health/ABCD Parent Demographics Survey.csv'\n",
    "\n",
    "#We will load stratification data from here\n",
    "test_strat_loc = nda_dr + 'Other Non-Imaging/ABCD ACS Post Stratification Weights.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to define the class object, which we will use to load load and to train/test different ML models.\n",
    "There are a few global parameters which we can optionally set when defining this object as well, lets look and see what they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module ABCD_ML.ABCD_ML:\n",
      "\n",
      "__init__(self, eventname='baseline_year_1_arm_1', use_default_subject_ids=True, default_na_values=['777', '999'], n_jobs=1, original_targets_key='targets', low_memory_mode=False, verbose=True)\n",
      "    Main class init\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    eventname : str or None, optional\n",
      "        Optional value to provide, specifying to keep certain rows\n",
      "        when reading data based on the eventname flag.\n",
      "        As ABCD is a longitudinal study, this flag lets you select only\n",
      "        one specific time point, or if set to None, will load everything.\n",
      "        (default = baseline_year_1_arm_1)\n",
      "    \n",
      "    use_default_subject_ids : bool, optional\n",
      "        Flag to determine the usage of 'default' subject id behavior.\n",
      "        If set to True, this will convert input NDAR subject ids\n",
      "        into upper case, with prepended NDAR_ - type format.\n",
      "        If set to False, then all input subject names must be entered\n",
      "        explicitly the same, no preprocessing will be done on them.\n",
      "        (default = True)\n",
      "    \n",
      "    default_na_values : list, optional\n",
      "        Additional values to treat as NaN, by default ABCD specific\n",
      "        values of '777' and '999' are treated as NaN,\n",
      "        and those set to default by pandas 'read_csv' function.\n",
      "        Note: if new values are passed here,\n",
      "        it will override these default '777' and '999' NaN values.\n",
      "        (default = ['777', '999'])\n",
      "    \n",
      "    n_jobs : int, optional\n",
      "        Number of processors to use during training\n",
      "        of machine learning models. This default parameter can\n",
      "        still be overriden if n_jobs is passed in\n",
      "        extra params in a specific training instance.\n",
      "        (default = 1)\n",
      "    \n",
      "    original_targets_key : str, optional\n",
      "        This parameter refers to the column name / key, that the\n",
      "        target variable of interest will be stored under. There are not a\n",
      "        lot of reasons to change this setting, except in the case of\n",
      "        a naming conflict - or just for further customization.\n",
      "        (default = 'targets')\n",
      "    \n",
      "    low_memory_mode : bool, optional\n",
      "        This parameter dictates behavior around loading in data,\n",
      "        specifically, if `low_memory_mode` is set to True,\n",
      "        then when loading data from multiple sources, only common\n",
      "        subjects will be saved as each data source is loaded.\n",
      "        For comparison, when low memory mode if off, the dropping\n",
      "        of non-common subjects occurs later. Non low memory mode\n",
      "        behavior is useful when the user wants to try loading different\n",
      "        data, and doesn't want automatic drops to occur.\n",
      "        If set to True, individual dataframes self.data, self.covars ect...\n",
      "        will also be deleted from memory as soon as modeling begins.\n",
      "        (default = False)\n",
      "    \n",
      "    verbose: bool, optional\n",
      "        If set to true will display diagnostic and other output during\n",
      "        dataloading and model training ect... if set to False this output\n",
      "        will be muted.\n",
      "        (default = True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ABCD_ML.ABCD_ML.__init__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the default parameters are okay for this simple example, but any of them can be changed. Let's change n_jobs to 4 instead of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCD_ML object initialized\n"
     ]
    }
   ],
   "source": [
    "ML = ABCD_ML.ABCD_ML(n_jobs = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can continue by optionally loading in a name map, which is simply a dictionary that attempts to rename any column names loaded in, if those column names are a key in the dictionary. This is useful for ABCD data as the default column names might not be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded map file\n"
     ]
    }
   ],
   "source": [
    "ML.load_name_map(loc = test_mapping_loc,\n",
    "                 source_name_col = \"NDAR name\",\n",
    "                 target_name_col = \"REDCap name/NDA alias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at what exactly is in this dictionary if we want to confirm we loaded it correctly.\n",
    "It is loaded as name_map within the ABCD_ML class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ddtidp_674': 'dmri_dtifagm_cortdestrieux_ssuborbitallh',\n",
       " 'ddtidp_748': 'dmri_dtifagm_cortdestrieux_ssuborbitalrh',\n",
       " 'ddtidp_675': 'dmri_dtifagm_cortdestrieux_ssubparietallh',\n",
       " 'ddtidp_749': 'dmri_dtifagm_cortdestrieux_ssubparietalrh',\n",
       " 'ddtidp_676': 'dmri_dtifagm_cortdestrieux_stemporalinflh',\n",
       " 'ddtidp_750': 'dmri_dtifagm_cortdestrieux_stemporalinfrh',\n",
       " 'ddtidp_677': 'dmri_dtifagm_cortdestrieux_stemporalsuplh',\n",
       " 'ddtidp_751': 'dmri_dtifagm_cortdestrieux_stemporalsuprh',\n",
       " 'ddtidp_678': 'dmri_dtifagm_cortdestrieux_stemporaltransverselh',\n",
       " 'ddtidp_752': 'dmri_dtifagm_cortdestrieux_stemporaltransverserh',\n",
       " 'dmri_dtifagwc_cdsn_bslh': 'dmri_dtifagwc_cortdesikan_banksstslh',\n",
       " 'dmri_dtifagwc_cdsn_bsrh': 'dmri_dtifagwc_cortdesikan_banksstsrh',\n",
       " 'dmri_dtifagwc_cdsn_cdacatelh': 'dmri_dtifagwc_cortdesikan_caudalanteriorcingulatelh',\n",
       " 'dmri_dtifagwc_cdsn_cdacaterh': 'dmri_dtifagwc_cortdesikan_caudalanteriorcingulaterh',\n",
       " 'dmri_dtifagwc_cdsn_cdmflh': 'dmri_dtifagwc_cortdesikan_caudalmiddlefrontallh',\n",
       " 'dmri_dtifagwc_cdsn_cdmfrh': 'dmri_dtifagwc_cortdesikan_caudalmiddlefrontalrh',\n",
       " 'dmri_dtifagwc_cdsn_cuneuslh': 'dmri_dtifagwc_cortdesikan_cuneuslh',\n",
       " 'dmri_dtifagwc_cdsn_cuneusrh': 'dmri_dtifagwc_cortdesikan_cuneusrh',\n",
       " 'dmri_dtifagwc_cdsn_ehinallh': 'dmri_dtifagwc_cortdesikan_entorhinallh',\n",
       " 'dmri_dtifagwc_cdsn_ehinalrh': 'dmri_dtifagwc_cortdesikan_entorhinalrh'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_examples = {k: ML.name_map[k] for k in list(ML.name_map)[300:320]}\n",
    "some_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load in the actual data. Like before we can check what parameters this function wants / can accept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method load_data in module ABCD_ML._Data:\n",
      "\n",
      "load_data(loc, dataset_type, drop_keys=[], filter_outlier_percent=None, winsorize_val=None) method of ABCD_ML.ABCD_ML.ABCD_ML instance\n",
      "    Load a ABCD2p0NDA (default) or 2.0_ABCD_Data_Explorer (explorer)\n",
      "    release formatted neuroimaging dataset - of derived ROI level info.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    loc : str, Path or None\n",
      "        The location of the csv file to load data load from.\n",
      "    \n",
      "    dataset_type : {'default', 'explorer', 'custom'}, optional\n",
      "        The type of dataset to load from. Where,\n",
      "    \n",
      "        - 'default' : ABCD2p0NDA style, (.txt and tab seperated)\n",
      "            The 4 columns before 'src_subject_id' and the 4 after,\n",
      "            (typically the default columns, and therefore not neuroimaging\n",
      "            data - also not including the eventname column), will be dropped.\n",
      "    \n",
      "        - 'explorer' : 2.0_ABCD_Data_Explorer tyle (.csv and comma seperated)\n",
      "            The first 2 columns before 'src_subject_id'\n",
      "            (typically the default columns, and therefore not neuroimaging\n",
      "            data - also not including the eventname column), will be dropped.\n",
      "    \n",
      "        - 'custom' : A user-defined custom dataset. Right now this is only\n",
      "            supported as a comma seperated file, with the subject names in a\n",
      "            column called 'src_subject_id'. No columns will be dropped,\n",
      "            unless specific drop keys are passed.\n",
      "    \n",
      "        (default = 'default')\n",
      "    \n",
      "    drop_keys : list, optional\n",
      "        A list of keys to drop columns by, where if any key given in a columns\n",
      "        name, then that column will be dropped.\n",
      "        (Note: if a name mapping exists, this drop step will be\n",
      "        conducted after renaming)\n",
      "        (default = [])\n",
      "    \n",
      "    filter_outlier_percent : int, float, tuple or None, optional\n",
      "        For float / ordinal data only.\n",
      "        A percent of values to exclude from either end of the\n",
      "        targets distribution, provided as either 1 number,\n",
      "        or a tuple (% from lower, % from higher).\n",
      "        set `filter_outlier_percent` to None for no filtering.\n",
      "        (default = None)\n",
      "        If over 1 then treated as a percent, if under 1, then\n",
      "        used directly.\n",
      "    \n",
      "    winsorize_val : float, tuple or None, optional\n",
      "        The (winsorize_val[0])th lowest values are set to\n",
      "        the (winsorize_val[0])th percentile,\n",
      "        and the (winsorize_val[1])th highest values\n",
      "        are set to the (1 - winsorize_val[1])th percentile.\n",
      "        If one value passed, used for both ends.\n",
      "        If None, then no winsorization performed.\n",
      "        Note: Winsorizing will be performed after\n",
      "        filtering for outliers if values are passed for both.\n",
      "        (default = None)\n",
      "    \n",
      "    Notes\n",
      "    ----------\n",
      "    For loading a truly custom dataset, an advanced user can\n",
      "    load all the data themselves into a pandas DataFrame.\n",
      "    They will need to have the DataFrame indexed by 'src_subject_id'\n",
      "    e.g., data = data.set_index('src_subject_id')\n",
      "    and subject ids will need to be in the correct style...\n",
      "    but if they do all this, then they can just set\n",
      "    self.data = whatever_they_loaded_their_data_as\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ML.load_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /mnt/sdb2/2.0_ABCD_Data_Explorer/2.0_NDA_Data/MRI/ABCD sMRI Part 1.csv assumed to be dataset type: explorer\n",
      "dropped ['abcd_smrip101_id', 'dataset_id', 'smri_visitid'] columns by default due to dataset type\n",
      "Dropped 0 columns, per drop_keys argument\n",
      "Dropped 522 rows for missing values\n",
      "Dropped rows with missing data\n",
      "Filtered data for outliers with value:  0.005\n",
      "Winsorized data with value:  0.01\n",
      "loaded shape:  (2099, 749)\n",
      "\n",
      "Total valid (overlapping subjects / not in exclusions)         subjects = 2099\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.load_data(loc=test_data_loc1,\n",
    "             dataset_type='explorer',\n",
    "             filter_outlier_percent=.005, # Let's filter out .5% from both sides of the distribution, why not\n",
    "             winsorize_val=.01)           # And then winsorize 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
