{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook goes through a simple binary classification example, explaining general library functionality and data loading along the way.\n",
    "\n",
    "We perform binary classification on sex, using structural MRI rois."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from ABCD_ML.ABCD_ML import ABCD_ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace these values below with your own directory / desired files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define directory with the 2.0_NDA_Data\n",
    "nda_dr = '/mnt/sdb2/2.0_ABCD_Data_Explorer/2.0_NDA_Data/'\n",
    "\n",
    "#This file stores the name mapping\n",
    "test_mapping_loc = nda_dr + 'ABCD_Release_ Notes_Data_Release_ 2.0/22. ABCD_Release_2.0_mapping_r.csv'\n",
    "\n",
    "#We will use as the neuroimaging data just the sMRI data\n",
    "test_data_loc1 = nda_dr + 'MRI/ABCD sMRI Part 1.csv'\n",
    "test_data_loc2 = nda_dr + 'MRI/ABCD sMRI Part 2.csv'\n",
    "\n",
    "#We will load target data (and covariate data) from here\n",
    "test_target_loc = nda_dr + 'Mental Health/ABCD Parent Demographics Survey.csv'\n",
    "\n",
    "#We will load stratification data from here\n",
    "test_strat_loc = nda_dr + 'Other Non-Imaging/ABCD ACS Post Stratification Weights.csv'\n",
    "\n",
    "#We will load exclusions from here, it is the list of flipped subject ids\n",
    "test_exclusion_loc = '/home/sage/bader_things/invalid_pguids.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to define the class object, which we will use to load load and to train/test different ML models.\n",
    "There are a few global parameters which we can optionally set when defining this object as well, lets look and see what they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module ABCD_ML.ABCD_ML:\n",
      "\n",
      "__init__(self, exp_name='some_exp', log_dr='', existing_log='new', verbose=True, notebook=True, subject_id='src_subject_id', eventname='baseline_year_1_arm_1', use_default_subject_ids=True, default_dataset_type='basic', default_na_values=['777', '999'], original_targets_key='targets', low_memory_mode=False, random_state=None)\n",
      "    Main class init\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    exp_name : str, optional\n",
      "        The name of this experimental run,\n",
      "        used explicitly in saving logs, and figures.\n",
      "        If log_dr is not set to None-\n",
      "        (if not None then saves logs and figures)\n",
      "        then a folder is created within the log dr\n",
      "        with the exp_name.\n",
      "    \n",
      "        (default = 'some_exp')\n",
      "    \n",
      "    log_dr : str, Path or None, optional\n",
      "        The directory in which to store logs...\n",
      "        If set to None, then will not save any logs!\n",
      "        If set to '', will save in the current dr.\n",
      "    \n",
      "        (default = '')\n",
      "    \n",
      "    existing_log : {'new', 'append', 'overwrite'}, optional\n",
      "        By default, if an exp_name folder already\n",
      "        exists within the log_dr, then the exp_name will\n",
      "        be incremented until a free name is avaliable.\n",
      "        This behavior is existing_log is 'new',\n",
      "        If existing_log is 'append' then log entries\n",
      "        and new figures will be added to the existing folder.\n",
      "        If existing_log is 'overwrite', then the existing\n",
      "        log folder with the same exp_name will be cleared\n",
      "        upon __init__.\n",
      "    \n",
      "        (default = 'new')\n",
      "    \n",
      "    verbose: bool, optional\n",
      "        If set to true will print diagnostic and other output during\n",
      "        dataloading and model training ect... if set to False this output\n",
      "        will not print. If log_dr is not None, then will still\n",
      "        record as log output.\n",
      "    \n",
      "        (default = True)\n",
      "    \n",
      "    notebook : bool, optional\n",
      "        If True, then assumes the user is running\n",
      "        the code in an interactive notebook. In this case,\n",
      "        any plots will be showed interactively\n",
      "        (as well as saved as long as log_dr != None)\n",
      "    \n",
      "    subject_id : str, optional\n",
      "        The name of the column with unique subject ids in different\n",
      "        dataset, for default ABCD datasets this is 'src_subject_id',\n",
      "        but if a user wanted to load and work with a different dataset,\n",
      "        they just need to change this accordingly\n",
      "        (in addition to setting eventname most likely to None and\n",
      "        use_default_subject_ids to False)\n",
      "    \n",
      "        (default = 'src_subject_id')\n",
      "    \n",
      "    eventname : str or None, optional\n",
      "        Optional value to provide, specifying to keep certain rows\n",
      "        when reading data based on the eventname flag.\n",
      "        As ABCD is a longitudinal study, this flag lets you select only\n",
      "        one specific time point, or if set to None, will load everything.\n",
      "    \n",
      "        (default = 'baseline_year_1_arm_1')\n",
      "    \n",
      "    use_default_subject_ids : bool, optional\n",
      "        Flag to determine the usage of 'default' subject id behavior.\n",
      "        If set to True, this will convert input NDAR subject ids\n",
      "        into upper case, with prepended NDAR - type format.\n",
      "        If set to False, then all input subject names must be entered\n",
      "        explicitly the same, no preprocessing will be done on them.\n",
      "    \n",
      "        (default = True)\n",
      "    \n",
      "    default_dataset_type : {'basic', 'explorer', 'custom'}, optional\n",
      "        The default dataset_type / file-type to load from.\n",
      "        Dataset types are,\n",
      "    \n",
      "        - 'basic' : ABCD2p0NDA style (.txt and tab seperated)\n",
      "    \n",
      "        - 'explorer' : 2.0_ABCD_Data_Explorer style                            (.csv and comma seperated)\n",
      "    \n",
      "        - 'custom' : A user-defined custom dataset. Right now this is only                supported as a comma seperated file, with the subject names in                a column called self.subject_id.\n",
      "    \n",
      "        (default = 'basic')\n",
      "    \n",
      "    default_na_values : list, optional\n",
      "        Additional values to treat as NaN, by default ABCD specific\n",
      "        values of '777' and '999' are treated as NaN,\n",
      "        and those set to default by pandas 'read_csv' function.\n",
      "        Note: if new values are passed here,\n",
      "        it will override these default '777' and '999' NaN values.\n",
      "    \n",
      "        (default = ['777', '999'])\n",
      "    \n",
      "    original_targets_key : str, optional\n",
      "        This parameter refers to the column name / key, that the\n",
      "        target variable of interest will be stored under. There are not a\n",
      "        lot of reasons to change this setting, except in the case of\n",
      "        a naming conflict - or just for further customization.\n",
      "    \n",
      "        (default = 'targets')\n",
      "    \n",
      "    low_memory_mode : bool, optional\n",
      "        This parameter dictates behavior around loading in data,\n",
      "        specifically, if `low_memory_mode` is set to True,\n",
      "        then when loading data from multiple sources, only common\n",
      "        subjects will be saved as each data source is loaded.\n",
      "        For comparison, when low memory mode if off, the dropping\n",
      "        of non-common subjects occurs later. Though regardless of if low\n",
      "        memory mode is on or off, subjects will be dropped right away\n",
      "        when exclusions or strat is loaded. Non-low memory mode\n",
      "        behavior is useful when the user wants to try loading different\n",
      "        data, and doesn't want automatic drops to occur.\n",
      "        If set to True, individual dataframes self.data, self.covars ect...\n",
      "        will also be deleted from memory as soon as modeling begins.\n",
      "    \n",
      "        This parameter also controls the pandas read_csv behavior,\n",
      "        which also has a low_memory flag.\n",
      "    \n",
      "        (default = False)\n",
      "    \n",
      "    random_state : int, RandomState instance or None, optional\n",
      "        The default random state, either as int for a specific seed,\n",
      "        or if None then the random seed is set by np.random.\n",
      "    \n",
      "        (default = None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ABCD_ML.__init__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the default parameters are okay for this simple example, but any of them can be changed.\n",
    "\n",
    "One thing we want to change just to make things easier is setting the default_dataset_type field, as in this example all of the datasets we are loading from are 'explorer' type. This way we won't have to pass that to every loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name = some_exp\n",
      "log_dr = /home/sage/ABCD_ML/Examples\n",
      "existing_log = overwrite\n",
      "verbose = True\n",
      "exp log dr setup at: /home/sage/ABCD_ML/Examples/some_exp\n",
      "log file at: /home/sage/ABCD_ML/Examples/some_exp/logs.txt\n",
      "notebook = True\n",
      "default subject id col = src_subject_id\n",
      "eventname = baseline_year_1_arm_1\n",
      "use default subject ids = True\n",
      "default dataset type = explorer\n",
      "default NaN values = ['777', '999']\n",
      "original targets key col = targets\n",
      "low memory mode = False\n",
      "random state = None\n",
      "ABCD_ML object initialized\n"
     ]
    }
   ],
   "source": [
    "ML = ABCD_ML(default_dataset_type='explorer', existing_log='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit the sklearn documentation for more info on most of the dif. models\n",
      "Note: Param distributions with a Rand Distribution\n",
      "cannot be used in search_type = \"grid\"\n",
      "\n",
      "Avaliable for Problem Type: binary\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "DecisionTreeClassifier (\"dt classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base dt\"\n",
      "None\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"dt rs\"\n",
      "max_depth: Random Integer Distribution (1, 19)\n",
      "min_samples_split: Random Integer Distribution (2, 49)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "LogisticRegression (\"elastic net logistic\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base elastic\"\n",
      "solver: saga\n",
      "max_iter: 5000\n",
      "multi_class: auto\n",
      "penalty: elasticnet\n",
      "l1_ratio: 0.5\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"elastic classifier\"\n",
      "solver: saga\n",
      "max_iter: 5000\n",
      "multi_class: auto\n",
      "penalty: elasticnet\n",
      "l1_ratio: Uniform/Reciprocal Distribution Over (0.0, 1.0)\n",
      "C: Uniform/Reciprocal Distribution Over (0.0001, 10000.0)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "GaussianNB (\"gaussian nb\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base gnb\"\n",
      "var_smoothing: 1e-09\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "GaussianProcessClassifier (\"gp classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base gp classifier\"\n",
      "n_restarts_optimizer: 5\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "KNeighborsClassifier (\"knn classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base knn\"\n",
      "n_neighbors: 5\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"knn rs\"\n",
      "weights: ['uniform', 'distance']\n",
      "n_neighbors: Random Integer Distribution (2, 19)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "LogisticRegression (\"lasso logistic\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base lasso\"\n",
      "solver: saga\n",
      "max_iter: 5000\n",
      "multi_class: auto\n",
      "penalty: l1\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"lasso C\"\n",
      "solver: saga\n",
      "max_iter: 5000\n",
      "multi_class: auto\n",
      "penalty: l1\n",
      "C: Uniform/Reciprocal Distribution Over (0.0001, 10000.0)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "LGBMClassifier (\"light gbm classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base lgbm\"\n",
      "silent: True\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"lgbm rs\"\n",
      "silent: True\n",
      "boosting_type: ['gbdt', 'dart', 'goss']\n",
      "n_estimators: Random Integer Distribution (3, 499)\n",
      "num_leaves: Random Integer Distribution (6, 49)\n",
      "min_child_samples: Random Integer Distribution (100, 499)\n",
      "min_child_weight: Uniform/Reciprocal Distribution Over (1e-05, 10000.0)\n",
      "subsample: Uniform/Reciprocal Distribution Over (0.2, 1.0)\n",
      "colsample_bytree: Uniform/Reciprocal Distribution Over (0.4, 1.0)\n",
      "reg_alpha: Uniform/Reciprocal Distribution Over (0.1, 100.0)\n",
      "reg_lambda: Uniform/Reciprocal Distribution Over (0.1, 100.0)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "LogisticRegression (\"logistic\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base logistic\"\n",
      "solver: saga\n",
      "max_iter: 5000\n",
      "multi_class: auto\n",
      "penalty: none\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "MLPClassifier (\"mlp classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base mlp\"\n",
      "None\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"mlp rs\"\n",
      "hidden_layer_sizes: Too many params to print\n",
      "activation: ['identity', 'logistic', 'tanh', 'relu']\n",
      "alpha: Uniform/Reciprocal Distribution Over (1e-05, 100.0)\n",
      "batch_size: Random Integer Distribution (2, 199)\n",
      "learning_rate: ['constant', 'invscaling', 'adaptive']\n",
      "learning_rate_init: Uniform/Reciprocal Distribution Over (1e-05, 0.01)\n",
      "max_iter: Random Integer Distribution (100, 499)\n",
      "beta_1: Uniform/Reciprocal Distribution Over (0.5, 1.0)\n",
      "beta_2: Uniform/Reciprocal Distribution Over (0.5, 1.0)\n",
      "\n",
      "\n",
      "2:\n",
      "\n",
      "\"mlp rs es\"\n",
      "hidden_layer_sizes: Too many params to print\n",
      "activation: ['identity', 'logistic', 'tanh', 'relu']\n",
      "alpha: Uniform/Reciprocal Distribution Over (1e-05, 100.0)\n",
      "batch_size: Random Integer Distribution (2, 199)\n",
      "learning_rate: ['constant', 'invscaling', 'adaptive']\n",
      "learning_rate_init: Uniform/Reciprocal Distribution Over (1e-05, 0.01)\n",
      "max_iter: Random Integer Distribution (100, 499)\n",
      "beta_1: Uniform/Reciprocal Distribution Over (0.5, 1.0)\n",
      "beta_2: Uniform/Reciprocal Distribution Over (0.5, 1.0)\n",
      "early_stopping: True\n",
      "n_iter_no_change: Random Integer Distribution (5, 49)\n",
      "\n",
      "\n",
      "3:\n",
      "\n",
      "\"mlp layers search\"\n",
      "hidden_layer_sizes: Too many params to print\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "RandomForestClassifier (\"random forest classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base rf\"\n",
      "n_estimators: 100\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"rf rs\"\n",
      "n_estimators: Random Integer Distribution (3, 499)\n",
      "max_depth: Random Integer Distribution (2, 199)\n",
      "max_features: Uniform/Reciprocal Distribution Over (0.0, 1.0)\n",
      "min_samples_split: Uniform/Reciprocal Distribution Over (0.0, 1.0)\n",
      "bootstrap: True\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "LogisticRegression (\"ridge logistic\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base ridge\"\n",
      "solver: saga\n",
      "max_iter: 5000\n",
      "multi_class: auto\n",
      "penalty: l2\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"ridge C\"\n",
      "solver: saga\n",
      "max_iter: 5000\n",
      "multi_class: auto\n",
      "penalty: l2\n",
      "C: Uniform/Reciprocal Distribution Over (0.0001, 10000.0)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "SVC (\"svm classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base svm classifier\"\n",
      "kernel: rbf\n",
      "gamma: scale\n",
      "probability: True\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"svm classifier rs\"\n",
      "kernel: rbf\n",
      "gamma: Uniform/Reciprocal Distribution Over (1e-06, 0.1)\n",
      "C: Uniform/Reciprocal Distribution Over (0.0001, 10000.0)\n",
      "probability: True\n",
      "\n",
      "-------------\n",
      "\n",
      "Avaliable for Problem Type: regression\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "DecisionTreeRegressor (\"dt regressor\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base dt\"\n",
      "None\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"dt rs\"\n",
      "max_depth: Random Integer Distribution (1, 19)\n",
      "min_samples_split: Random Integer Distribution (2, 49)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "ElasticNet (\"elastic net regressor\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base elastic net\"\n",
      "max_iter: 5000\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"elastic regression\"\n",
      "max_iter: 5000\n",
      "alpha: Uniform/Reciprocal Distribution Over (1e-05, 100.0)\n",
      "l1_ratio: Uniform/Reciprocal Distribution Over (0.0, 1.0)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "GaussianProcessRegressor (\"gp regressor\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base gp regressor\"\n",
      "n_restarts_optimizer: 5\n",
      "normalize_y: True\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "KNeighborsRegressor (\"knn regressor\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base knn\"\n",
      "n_neighbors: 5\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"knn rs\"\n",
      "weights: ['uniform', 'distance']\n",
      "n_neighbors: Random Integer Distribution (2, 19)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "LGBMRegressor (\"light gbm regressor\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base lgbm\"\n",
      "silent: True\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"lgbm rs\"\n",
      "silent: True\n",
      "boosting_type: ['gbdt', 'dart', 'goss']\n",
      "n_estimators: Random Integer Distribution (3, 499)\n",
      "num_leaves: Random Integer Distribution (6, 49)\n",
      "min_child_samples: Random Integer Distribution (100, 499)\n",
      "min_child_weight: Uniform/Reciprocal Distribution Over (1e-05, 10000.0)\n",
      "subsample: Uniform/Reciprocal Distribution Over (0.2, 1.0)\n",
      "colsample_bytree: Uniform/Reciprocal Distribution Over (0.4, 1.0)\n",
      "reg_alpha: Uniform/Reciprocal Distribution Over (0.1, 100.0)\n",
      "reg_lambda: Uniform/Reciprocal Distribution Over (0.1, 100.0)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "EarlyStopLGBMRegressor (\"light gbm regressor early stop\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base lgbm es\"\n",
      "silent: True\n",
      "val_split_percent: 0.1\n",
      "early_stop_rounds: 50\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"lgbm es rs\"\n",
      "silent: True\n",
      "boosting_type: ['gbdt', 'dart', 'goss']\n",
      "n_estimators: Random Integer Distribution (3, 499)\n",
      "num_leaves: Random Integer Distribution (6, 49)\n",
      "min_child_samples: Random Integer Distribution (100, 499)\n",
      "min_child_weight: Uniform/Reciprocal Distribution Over (1e-05, 10000.0)\n",
      "subsample: Uniform/Reciprocal Distribution Over (0.2, 1.0)\n",
      "colsample_bytree: Uniform/Reciprocal Distribution Over (0.4, 1.0)\n",
      "reg_alpha: Uniform/Reciprocal Distribution Over (0.1, 100.0)\n",
      "reg_lambda: Uniform/Reciprocal Distribution Over (0.1, 100.0)\n",
      "val_split_percent: Uniform/Reciprocal Distribution Over (0.05, 0.25)\n",
      "early_stop_rounds: Random Integer Distribution (10, 149)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "LinearRegression (\"linear regressor\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base linear\"\n",
      "fit_intercept: True\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "MLPRegressor (\"mlp regressor\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base mlp\"\n",
      "None\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"mlp rs\"\n",
      "hidden_layer_sizes: Too many params to print\n",
      "activation: ['identity', 'logistic', 'tanh', 'relu']\n",
      "alpha: Uniform/Reciprocal Distribution Over (1e-05, 100.0)\n",
      "batch_size: Random Integer Distribution (2, 199)\n",
      "learning_rate: ['constant', 'invscaling', 'adaptive']\n",
      "learning_rate_init: Uniform/Reciprocal Distribution Over (1e-05, 0.01)\n",
      "max_iter: Random Integer Distribution (100, 499)\n",
      "beta_1: Uniform/Reciprocal Distribution Over (0.5, 1.0)\n",
      "beta_2: Uniform/Reciprocal Distribution Over (0.5, 1.0)\n",
      "\n",
      "\n",
      "2:\n",
      "\n",
      "\"mlp rs es\"\n",
      "hidden_layer_sizes: Too many params to print\n",
      "activation: ['identity', 'logistic', 'tanh', 'relu']\n",
      "alpha: Uniform/Reciprocal Distribution Over (1e-05, 100.0)\n",
      "batch_size: Random Integer Distribution (2, 199)\n",
      "learning_rate: ['constant', 'invscaling', 'adaptive']\n",
      "learning_rate_init: Uniform/Reciprocal Distribution Over (1e-05, 0.01)\n",
      "max_iter: Random Integer Distribution (100, 499)\n",
      "beta_1: Uniform/Reciprocal Distribution Over (0.5, 1.0)\n",
      "beta_2: Uniform/Reciprocal Distribution Over (0.5, 1.0)\n",
      "early_stopping: True\n",
      "n_iter_no_change: Random Integer Distribution (5, 49)\n",
      "\n",
      "\n",
      "3:\n",
      "\n",
      "\"mlp layers search\"\n",
      "hidden_layer_sizes: Too many params to print\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "RandomForestRegressor (\"random forest regressor\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base rf\"\n",
      "n_estimators: 100\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"rf rs\"\n",
      "n_estimators: Random Integer Distribution (3, 499)\n",
      "max_depth: Random Integer Distribution (2, 199)\n",
      "max_features: Uniform/Reciprocal Distribution Over (0.0, 1.0)\n",
      "min_samples_split: Uniform/Reciprocal Distribution Over (0.0, 1.0)\n",
      "bootstrap: True\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "SVR (\"svm regressor\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base svm\"\n",
      "kernel: rbf\n",
      "gamma: scale\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"svm rs\"\n",
      "kernel: rbf\n",
      "gamma: Uniform/Reciprocal Distribution Over (1e-06, 0.1)\n",
      "C: Uniform/Reciprocal Distribution Over (0.0001, 10000.0)\n",
      "\n",
      "-------------\n",
      "\n",
      "Avaliable for Problem Type: categorical multilabel\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "DecisionTreeClassifier (\"dt classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base dt\"\n",
      "None\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"dt rs\"\n",
      "max_depth: Random Integer Distribution (1, 19)\n",
      "min_samples_split: Random Integer Distribution (2, 49)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "KNeighborsClassifier (\"knn classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base knn\"\n",
      "n_neighbors: 5\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"knn rs\"\n",
      "weights: ['uniform', 'distance']\n",
      "n_neighbors: Random Integer Distribution (2, 19)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "MLPClassifier (\"mlp classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base mlp\"\n",
      "None\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"mlp rs\"\n",
      "hidden_layer_sizes: Too many params to print\n",
      "activation: ['identity', 'logistic', 'tanh', 'relu']\n",
      "alpha: Uniform/Reciprocal Distribution Over (1e-05, 100.0)\n",
      "batch_size: Random Integer Distribution (2, 199)\n",
      "learning_rate: ['constant', 'invscaling', 'adaptive']\n",
      "learning_rate_init: Uniform/Reciprocal Distribution Over (1e-05, 0.01)\n",
      "max_iter: Random Integer Distribution (100, 499)\n",
      "beta_1: Uniform/Reciprocal Distribution Over (0.5, 1.0)\n",
      "beta_2: Uniform/Reciprocal Distribution Over (0.5, 1.0)\n",
      "\n",
      "\n",
      "2:\n",
      "\n",
      "\"mlp rs es\"\n",
      "hidden_layer_sizes: Too many params to print\n",
      "activation: ['identity', 'logistic', 'tanh', 'relu']\n",
      "alpha: Uniform/Reciprocal Distribution Over (1e-05, 100.0)\n",
      "batch_size: Random Integer Distribution (2, 199)\n",
      "learning_rate: ['constant', 'invscaling', 'adaptive']\n",
      "learning_rate_init: Uniform/Reciprocal Distribution Over (1e-05, 0.01)\n",
      "max_iter: Random Integer Distribution (100, 499)\n",
      "beta_1: Uniform/Reciprocal Distribution Over (0.5, 1.0)\n",
      "beta_2: Uniform/Reciprocal Distribution Over (0.5, 1.0)\n",
      "early_stopping: True\n",
      "n_iter_no_change: Random Integer Distribution (5, 49)\n",
      "\n",
      "\n",
      "3:\n",
      "\n",
      "\"mlp layers search\"\n",
      "hidden_layer_sizes: Too many params to print\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "RandomForestClassifier (\"random forest classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base rf\"\n",
      "n_estimators: 100\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"rf rs\"\n",
      "n_estimators: Random Integer Distribution (3, 499)\n",
      "max_depth: Random Integer Distribution (2, 199)\n",
      "max_features: Uniform/Reciprocal Distribution Over (0.0, 1.0)\n",
      "min_samples_split: Uniform/Reciprocal Distribution Over (0.0, 1.0)\n",
      "bootstrap: True\n",
      "\n",
      "-------------\n",
      "\n",
      "Avaliable for Problem Type: categorical multiclass\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "DecisionTreeClassifier (\"dt classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base dt\"\n",
      "None\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"dt rs\"\n",
      "max_depth: Random Integer Distribution (1, 19)\n",
      "min_samples_split: Random Integer Distribution (2, 49)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "LogisticRegression (\"elastic net logistic\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base elastic\"\n",
      "solver: saga\n",
      "max_iter: 5000\n",
      "multi_class: auto\n",
      "penalty: elasticnet\n",
      "l1_ratio: 0.5\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"elastic classifier\"\n",
      "solver: saga\n",
      "max_iter: 5000\n",
      "multi_class: auto\n",
      "penalty: elasticnet\n",
      "l1_ratio: Uniform/Reciprocal Distribution Over (0.0, 1.0)\n",
      "C: Uniform/Reciprocal Distribution Over (0.0001, 10000.0)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "GaussianNB (\"gaussian nb\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base gnb\"\n",
      "var_smoothing: 1e-09\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "GaussianProcessClassifier (\"gp classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base gp classifier\"\n",
      "n_restarts_optimizer: 5\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "KNeighborsClassifier (\"knn classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base knn\"\n",
      "n_neighbors: 5\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"knn rs\"\n",
      "weights: ['uniform', 'distance']\n",
      "n_neighbors: Random Integer Distribution (2, 19)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "LogisticRegression (\"lasso logistic\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base lasso\"\n",
      "solver: saga\n",
      "max_iter: 5000\n",
      "multi_class: auto\n",
      "penalty: l1\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"lasso C\"\n",
      "solver: saga\n",
      "max_iter: 5000\n",
      "multi_class: auto\n",
      "penalty: l1\n",
      "C: Uniform/Reciprocal Distribution Over (0.0001, 10000.0)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "LGBMClassifier (\"light gbm classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base lgbm\"\n",
      "silent: True\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"lgbm rs\"\n",
      "silent: True\n",
      "boosting_type: ['gbdt', 'dart', 'goss']\n",
      "n_estimators: Random Integer Distribution (3, 499)\n",
      "num_leaves: Random Integer Distribution (6, 49)\n",
      "min_child_samples: Random Integer Distribution (100, 499)\n",
      "min_child_weight: Uniform/Reciprocal Distribution Over (1e-05, 10000.0)\n",
      "subsample: Uniform/Reciprocal Distribution Over (0.2, 1.0)\n",
      "colsample_bytree: Uniform/Reciprocal Distribution Over (0.4, 1.0)\n",
      "reg_alpha: Uniform/Reciprocal Distribution Over (0.1, 100.0)\n",
      "reg_lambda: Uniform/Reciprocal Distribution Over (0.1, 100.0)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "LogisticRegression (\"logistic\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base logistic\"\n",
      "solver: saga\n",
      "max_iter: 5000\n",
      "multi_class: auto\n",
      "penalty: none\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "MLPClassifier (\"mlp classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base mlp\"\n",
      "None\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"mlp rs\"\n",
      "hidden_layer_sizes: Too many params to print\n",
      "activation: ['identity', 'logistic', 'tanh', 'relu']\n",
      "alpha: Uniform/Reciprocal Distribution Over (1e-05, 100.0)\n",
      "batch_size: Random Integer Distribution (2, 199)\n",
      "learning_rate: ['constant', 'invscaling', 'adaptive']\n",
      "learning_rate_init: Uniform/Reciprocal Distribution Over (1e-05, 0.01)\n",
      "max_iter: Random Integer Distribution (100, 499)\n",
      "beta_1: Uniform/Reciprocal Distribution Over (0.5, 1.0)\n",
      "beta_2: Uniform/Reciprocal Distribution Over (0.5, 1.0)\n",
      "\n",
      "\n",
      "2:\n",
      "\n",
      "\"mlp rs es\"\n",
      "hidden_layer_sizes: Too many params to print\n",
      "activation: ['identity', 'logistic', 'tanh', 'relu']\n",
      "alpha: Uniform/Reciprocal Distribution Over (1e-05, 100.0)\n",
      "batch_size: Random Integer Distribution (2, 199)\n",
      "learning_rate: ['constant', 'invscaling', 'adaptive']\n",
      "learning_rate_init: Uniform/Reciprocal Distribution Over (1e-05, 0.01)\n",
      "max_iter: Random Integer Distribution (100, 499)\n",
      "beta_1: Uniform/Reciprocal Distribution Over (0.5, 1.0)\n",
      "beta_2: Uniform/Reciprocal Distribution Over (0.5, 1.0)\n",
      "early_stopping: True\n",
      "n_iter_no_change: Random Integer Distribution (5, 49)\n",
      "\n",
      "\n",
      "3:\n",
      "\n",
      "\"mlp layers search\"\n",
      "hidden_layer_sizes: Too many params to print\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "RandomForestClassifier (\"random forest classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base rf\"\n",
      "n_estimators: 100\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"rf rs\"\n",
      "n_estimators: Random Integer Distribution (3, 499)\n",
      "max_depth: Random Integer Distribution (2, 199)\n",
      "max_features: Uniform/Reciprocal Distribution Over (0.0, 1.0)\n",
      "min_samples_split: Uniform/Reciprocal Distribution Over (0.0, 1.0)\n",
      "bootstrap: True\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "LogisticRegression (\"ridge logistic\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base ridge\"\n",
      "solver: saga\n",
      "max_iter: 5000\n",
      "multi_class: auto\n",
      "penalty: l2\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"ridge C\"\n",
      "solver: saga\n",
      "max_iter: 5000\n",
      "multi_class: auto\n",
      "penalty: l2\n",
      "C: Uniform/Reciprocal Distribution Over (0.0001, 10000.0)\n",
      "\n",
      "-------------\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "SVC (\"svm classifier\")\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "\n",
      "Param Indices\n",
      "-------------\n",
      "\n",
      "0:\n",
      "\n",
      "\"base svm classifier\"\n",
      "kernel: rbf\n",
      "gamma: scale\n",
      "probability: True\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "\"svm classifier rs\"\n",
      "kernel: rbf\n",
      "gamma: Uniform/Reciprocal Distribution Over (1e-06, 0.1)\n",
      "C: Uniform/Reciprocal Distribution Over (0.0001, 10000.0)\n",
      "probability: True\n",
      "\n",
      "-------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML.Show_Models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can continue by optionally loading in a name map, which is simply a dictionary that attempts to rename any column names loaded in, if those column names are a key in the dictionary. This is useful for ABCD data as the default column names might not be useful.\n",
    "\n",
    "Note this name map and these parameters are for the 'ABCD 2.0 Explorer' formatting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Load_Name_Map(loc = test_mapping_loc,\n",
    "                 source_name_col = \"NDAR name\",\n",
    "                 target_name_col = \"REDCap name/NDA alias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at what exactly is in this dictionary if we want to confirm we loaded it correctly.\n",
    "It is loaded as name_map within the ABCD_ML class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_examples = {k: ML.name_map[k] for k in list(ML.name_map)[300:320]}\n",
    "some_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ML.Load_Exclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our exclusions we will just use the flipped subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Load_Exclusions(loc=test_exclusion_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load in the actual data. Like before we can check what parameters this function wants / can accept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ML.Load_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ML.Load_Data(loc=[test_data_loc1, test_data_loc2],\n",
    "             dataset_type='explorer',\n",
    "             filter_outlier_percent=.005, \n",
    "             winsorize_val=.01)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That ends up being a lot of data dropped just for dropping missing outliers... since we are not in low_memory_mode, we can just clear the data, and reload it. This time we will also load not just the first data loc, but the rest as well - and at the same time - but just providing the locations of both in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Clear_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Load_Data(loc=[test_data_loc1, test_data_loc2],\n",
    "             dataset_type='explorer', #This is set as default, but how we would specify it if we wanted to change i\n",
    "             filter_outlier_percent=.0005, \n",
    "             winsorize_val=.001)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These seem okay settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data for this expiriment should now be loaded. We can check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now that data is loaded we still need to load targets, and can optionally load covars, strat and exclusions. Lets load our target first, and begin as before by checking out the loading function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ML.Load_Targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, lets just load in sex as our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Load_Targets(loc=test_target_loc,\n",
    "                col_name='demo_sex_v2',\n",
    "                data_type='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you read the verbose print out above, you'll notice that it says \"More than two unique score values found,filtered all but [1. 2.]\" This is because by default when a binary datatype is passed, the dataloader needs to make sure it loads in only two unique values. To solve this when there exists outliers, like in this case, all but the top two unique values by count will be dropped. It will further show which values it has kept, in the case that an error was made, but here 1 and 2 are the correct sex values. If more than two values are desired, the categorical data type should be used.\n",
    "\n",
    "Let's look and see to make sure everything was loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look into adding covars next. Where co-variates arn't quite treated as typical co-variates, but are values we would like to be able to pass as additional input to the ML model if desired (and input that is treated in a special way, specifically covar input won't be scaled with any data scaler by default). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ML.Load_Covars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Load_Covars(loc=test_target_loc,\n",
    "               col_names = 'demo_ed_v2',\n",
    "               data_types = 'ordinal',\n",
    "               standardize = False,\n",
    "               normalize = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check to see it was loaded correctly (and normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.covars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will considering loading different stratification values. These are the values that we can optionally define custom validation / split behavior on. Within this example, we are just going to make sure that all splits preserve subjects with the same family id within the same fold, so lets load family id - after looking as the help function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ML.Load_Strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Load_Strat(loc=test_strat_loc,\n",
    "              col_names='rel_family_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.strat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we now have our data, targets, covars, strat and exclusions loaded (Noting that the minimum requiriments for running an ML expiriment are just data or covars and targets, the rest being optional). The actual length of the script is also not as terrible as it seems, and once loading behavior is confirmed, verbose can even be turned off. To show this, we can re-load everything as above with verbose off. (Commented out, but you get the idea~)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML = ABCD_ML.ABCD_ML(verbose = False) # Reloading the ML object itself to reset everything.\n",
    "\n",
    "#ML.Load_Exclusions(loc=test_exclusion_loc)\n",
    "\n",
    "#ML.Load_Name_Map(loc = test_mapping_loc,\n",
    "#                 source_name_col = \"NDAR name\",\n",
    "#                 target_name_col = \"REDCap name/NDA alias\")\n",
    "\n",
    "#ML.Load_Data(loc=[test_data_loc1, test_data_loc2],\n",
    "#             dataset_type='explorer',\n",
    "#             filter_outlier_percent=.0005, \n",
    "#             winsorize_val=.01)\n",
    "\n",
    "#ML.Load_Targets(loc=test_target_loc,\n",
    "#                col_name='demo_sex_v2',\n",
    "#                data_type='b')\n",
    "\n",
    "#ML.Load_Covars(loc=test_target_loc,\n",
    "#               col_names = 'demo_ed_v2',\n",
    "#               data_types = 'ordinal',\n",
    "#               standardize = False,\n",
    "#               normalize = True)\n",
    "\n",
    "#ML.Load_Strat(loc=test_strat_loc,\n",
    "#              col_names='rel_family_id')\n",
    "\n",
    "#ML.verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets move onto defining our validation stratagy (which is again optional, but as stated before for this example we are going to preserve family ids within the same folds), if no explicit validation strategy is defined, then random splits will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ML.Define_Validation_Strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for group preserving behavior, as we are interested in keep families within the same folds, we supply an argument for groups. Specifically, we use the name of the column loaded within self.strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Define_Validation_Strategy(groups='rel_family_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly before we get to modelling, we want to define a global train-test split, so that we can perform model exploration, and parameter tuning ect... on a training set, and leave a left-out testing set to eventually test with out final selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ML.Train_Test_Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Train_Test_Split(test_size=.25, #Let be somewhat conservative, and use a size of .25\n",
    "                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great - and because we set the validation stratagy to preserve family structure within the folds, we know that no family id is in both the train and test set - for the paranoid we can make sure of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = set(ML.strat['rel_family_id'].loc[ML.train_subjects])\n",
    "test_ids = set(ML.strat['rel_family_id'].loc[ML.test_subjects])\n",
    "\n",
    "print('Unique family ids in train: ', len(train_ids))\n",
    "print('Unique family ids in test: ', len(test_ids))\n",
    "print('Overlap : ', len(train_ids.intersection(test_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed to modeling.\n",
    "\n",
    "The main function we use here is Evaluate, we can look at its docstring, but from a very high level, this is the function we use to test different expirimental setups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ML.Evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check what different model types we have avaliable for binary first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Show_Model_Types(problem_type='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at different metrics avaliable for binary classification, and different data scalers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Show_Metrics(problem_type='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML.Show_Data_Scalers(show_scaler_help=False, show_default_params=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also set some default ML params for some of the settings that we will be keeping the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ML.Set_Default_ML_Params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters are mostly the same for setting default params as they are passed to Evaluate or Test. Importantly, by defining defaults, we define the value to be used if no value is passed to a given argument in Evaluate or Test.\n",
    "Lets set some."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Set_Default_ML_Params(problem_type = 'binary', #This will be staying the same\n",
    "                         metric = ['macro roc auc', 'f1', 'accuracy'], #Lets set a few\n",
    "                         data_scaler = 'standard', #Standard scaling is fine, but this can also be a list\n",
    "                         n_splits = 2, #For the sake of quick run-time and this example 2 splits, no repeats\n",
    "                         n_repeats = 1,\n",
    "                         int_cv = 3,\n",
    "                         class_weight = 'balanced', \n",
    "                         n_jobs = 8,\n",
    "                         n_iter = 8,\n",
    "                         random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some default ML params set, all we need to do to run an evaluation is simply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_scores = ML.Evaluate(model_type='rf',\n",
    "                         sampler='random over sampler',\n",
    "                         ensemble_type = 'basic ensemble',\n",
    "                         ensemble_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_scores = ML.Evaluate(model_type='rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try with multiple data scalers now, just to show off that functionality, and still just the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_scores = ML.Evaluate(model_type='logistic',\n",
    "             data_scaler = ['robust', 'minmax'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The robust scaler and minmax scaler seem to help a bit, so hey lets set that as our new default... just for fun.\n",
    "\n",
    "Note when setting a new param, you do not need to repass in everything you are not changing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Set_Default_ML_Params(data_scaler = ['robust', 'minmax'])\n",
    "\n",
    "# Let make just take a look at the new default params, to make sure it is as expected\n",
    "ML.default_ML_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run a more complicated classifier, in particular, let's\n",
    "try the light gradient boosting machine (LGBM) classifier, with a random search for parameters.\n",
    "Note: The ' rs' at the end of the str model indicator is a special key for selecting the random parameter search option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_scores = ML.Evaluate(model_type='lgbm classifier rs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, the basic logistic regression seems to perform better then the more complex gradient boosting. One thing to note though is that we only tested 8 random sets of hyperparamers, what if we tried exploring a larger number? (This might take a while, especially if you are not running this on a powerful computer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_scores = ML.Evaluate(model_type='lgbm classifier rs',\n",
    "                         n_iter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is still not all that big a boost from just a logistic regression.\n",
    "We can still explore some other linear classifiers though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_scores = ML.Evaluate(model_type='ridge logistic rs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_scores = ML.Evaluate(model_type='knn classifier gs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_scores = ML.Evaluate(model_type='gaussian nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a gaussian process classifier\n",
    "raw_scores = ML.Evaluate(model_type='gp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_scores = ML.Evaluate(model_type='elastic net logistic rs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could easily continue with the model exploration portion, but for this example, lets say we have explored enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.Test(model_type ='ridge logistic rs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
